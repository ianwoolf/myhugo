<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.14" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title> 起风了 &middot; 起风了 </title>

  
  <link rel="stylesheet" href="http://106.186.127.250:1313/blog/css/poole.css">
  <link rel="stylesheet" href="http://106.186.127.250:1313/blog/css/syntax.css">
  <link rel="stylesheet" href="http://106.186.127.250:1313/blog/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="http://106.186.127.250:1313/blog/index.xml" rel="alternate" type="application/rss+xml" title="起风了" />
</head>

<body class="">

<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
栏目</br>
<a href="/blog/docker">docker</h1></a></br>
<a href="/blog/生活">生活</h1></a></br>
<a href="/blog/golang">golang</h1></a></br>
<a href="/blog/linux">linux</h1></a></br>
<a href="/blog/python">python</h1></a></br>
<a href="/blog/监控">监控</h1></a></br>
</br><br>
</br><br>
</br><br>
</br><br>
      <a href="http://106.186.127.250:1313/blog/"><h1>起风了</h1></a>
      <p class="lead">
      把梦想埋在心中，走向沙漠。<br/>
<a href="http://106.186.127.250:9000/tt/dbmv/">我的restful<br></a>


    </div>

    <ul class="sidebar-nav">
      <li><a href="/blog">Home</a> </li>
      
    </ul>

    
  </div>
</div>


    <div class="content container">
<div class="posts">

      
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/%E7%94%9F%E6%B4%BB/%E6%96%B0%E5%8D%9A%E5%AE%A2/">
        新博客，新征程
      </a>
    </h1>

    <span class="post-date">Sun, Oct 20, 2115</span>

    <p>本博客用hugo搭建，用supervisord启动。
博文在<a href="https://github.com/ianwoolf/myPages">github</a>上，技术的东西欢迎讨论，如果有错误和补充，欢迎大家提issure或者pr。</p>

<p>博客主要用来记录自己的一些东西，之前旧博客(无闻的那个)里东西没有完全入git，还没怎么整理、入新博客。最近没太多时间整理，有时间吧。</p>

<p>个人github上没太多东西，个人一些东西后来都做到了公司的git里。有时间拆一拆，把个人的，无关公司的东西，整理一下。</p>

<p>博主是北漂devops一名，现在主要写go语言，做集中化运维 及 各种拓展的平台、工具。</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/python/%E6%A8%A1%E5%9D%97/argparse/">
        argparse 命令行参数解析模块
      </a>
    </h1>

    <span class="post-date">Mon, Dec 21, 2015</span>

    <p>python发展的时间很长,功能很全.是devops的得力工具.
我的python太弱了,一直想写python的东西,做个积累.一直没有做,从argparse开始吧.</p>

<pre><code>import argparse

parser = argparse.ArgumentParser()
parser.add_argument('--list', action='append', dest='list', help='append')
parser.add_argument('--false', action='store_false', dest='false',
    help='store_false')
parser.add_argument('--true', action='store_true', dest='true',
    help='stroe_true')
parser.add_argument('--foo', help='fault store action')

print parser.parse_args('--foo 2'.split())
#Namespace(false=True, foo='2', list=None, true=False)
print parser.parse_args('--foo x'.split())
#Namespace(false=True, foo='x', list=None, true=False)
print parser.parse_args('--false'.split())
#Namespace(false=False, foo=None, list=None, true=False)
print parser.parse_args('--true'.split())
#Namespace(false=True, foo=None, list=None, true=True)
print parser.parse_args('--list 1, --list 2'.split())
#Namespace(false=True, foo=None, list=['1,', '2'], true=False)
</code></pre>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/golang/golang%E7%9A%84%E9%94%81/">
        golang的锁
      </a>
    </h1>

    <span class="post-date">Wed, Nov 4, 2015</span>

    

<p>golang的锁分互斥锁和读写锁</p>

<h3 id="互斥锁:d68f9ca30f841459dc70d42042f9e0d7">互斥锁</h3>

<p>比较简单,这里先略过,以后有时间补上.</p>

<h3 id="读写锁:d68f9ca30f841459dc70d42042f9e0d7">读写锁</h3>

<p>读写锁是通过对unit32加减以及阻塞来完成对读锁和写锁的操作。</p>

<p>需要注意的一点是 加/放开 写锁会 =&gt; 锁住/解锁读写锁；
而读锁无限制，只是注意不要unlock超过lock的数量。</p>

<p>这两个函数会阻塞</p>

<p><code>func runtime_Semacquire(s *uint32)</code> =&gt; 用来等待解锁，解锁后加锁;</p>

<p><code>func runtime_Semrelease(s *uint32)</code> =&gt; 用来解锁，解锁后出发处于block的加锁动作</p>

<p>读写锁的部分源码,以后有时间补全注释</p>

<pre><code>type RWMutex struct {
    w           Mutex  // held if there are pending writers
// 计数,同时用来控制wait =&gt; 加减锁
    writerSem   uint32 // semaphore for writers to wait for completing readers
    readerSem   uint32 // semaphore for readers to wait for completing writers
    readerCount int32  // number of pending readers
    readerWait  int32  // number of departing readers
}

const rwmutexMaxReaders = 1 &lt;&lt; 30

// RLock locks rw for reading.
func (rw *RWMutex) RLock() {
    if raceenabled {
            _ = rw.w.state
            raceDisable()
    }
// 原子操作
    if atomic.AddInt32(&amp;rw.readerCount, 1) &lt; 0 {
// 这个地方用计数来控制wait
            runtime_Semacquire(&amp;rw.readerSem)
    }
    if raceenabled {
            raceEnable()
            raceAcquire(unsafe.Pointer(&amp;rw.readerSem))
    }
}
//  解锁类似

// 写锁的加锁
func (rw *RWMutex) Lock() {
    if raceenabled {
            _ = rw.w.state
            raceDisable()
    }
    rw.w.Lock()
//原子操作，线程安全
    r := atomic.AddInt32(&amp;rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders  
    if r != 0 &amp;&amp; atomic.AddInt32(&amp;rw.readerWait, r) != 0 {
// 可能会阻塞
            runtime_Semacquire(&amp;rw.writerSem)  
    }
    if raceenabled {
            raceEnable()
// 读锁  写锁  都被锁住
            raceAcquire(unsafe.Pointer(&amp;rw.readerSem)) // unsafe包获得指针
            raceAcquire(unsafe.Pointer(&amp;rw.writerSem))
    }
}
// 解锁类似
</code></pre>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/%E7%94%9F%E6%B4%BB/%E8%BE%9E%E9%80%80%E4%BD%A0%E4%B8%8E%E8%83%BD%E5%8A%9B%E6%97%A0%E5%85%B3/">
        【转】辞退你与能力无关
      </a>
    </h1>

    <span class="post-date">Wed, Oct 21, 2015</span>

    

<p>有云的地方，就是天下。有人的地方，就是江湖。在职场的江湖上，有能力的你是桀骜不驯还是顺应潮流，取决于你对规则的理解和敬意。</p>

<p>情景再现</p>

<p>从销售主管到总经理我一路走来，被人管也管过人，也辞退过员工。这多数是因为员工的能力无法胜任工作，但这次被辞退的员工并非没有能力。刚开始我是欣赏他的，甚至准备予以重用。但一次制度的调整，让我对他的态度急转直下。</p>

<p>为了加强考核，我对相关制度做了调整，谁知在宣布时该员工当场反对，会议还没有结束就擅自离去。更严重的是，他竟然挑拨其他人不工作来对抗。</p>

<p>第一天，我观察了他和这些员工的表现，第二天他们依然无动于衷。无奈中，我先找了被他挑动的员工谈话，他们表示考核的调整的确给他们带来压力，但将会积极开展工作。最后我和他谈话也希望这是良性的沟通，但他依然态度强硬并且发出挑衅，如果我不调整制度，他就要和所挑动的员工一起离开。</p>

<p>最终，我作出了辞退他的决定，曾被他挑拨的员工也情绪稳定的开展了工作。在职场的江湖上，有能力的你是桀骜不驯还是顺应潮流，这取决于你对规则的理解和敬意。</p>

<h2 id="规则1-学会尊敬和服从上级:774be0051f1b4f02143bd69cbb43e499">规则1：学会尊敬和服从上级</h2>

<p>职场之所以会有上下级，是为了保证团队工作的开展。上级掌握了一定的资源和权力，考虑问题是从团队角度考虑而难以兼顾到个体。尊敬和服从上级是确保团队完成目标的重要条件。员工不站在团队的高度来思考问题，只站在自己的角度去找上级的麻烦甚至恃才傲物，这样的员工很难生存更谈不上走得好远。</p>

<h2 id="规则2-如果你的工作不能达到上级的要求-一定要及时和上级沟通:774be0051f1b4f02143bd69cbb43e499">规则2：如果你的工作不能达到上级的要求，一定要及时和上级沟通</h2>

<p>在实际工作中，有的工作需要一定的时间来保证。可能在一定时期内你的工作还没有让别人看到显着成绩，这时不要和你的上级距离太远，要创造条件去和他沟通，要让他知道你的进度和计划和要取得的成绩。你这样做了上级不会责备你，他还会利用所掌握的资源给你帮助，让你提前取得业绩。</p>

<p>然而，有的职场新手甚至老手容易犯的错误却是，越是没有成绩越是不愿去找上级沟通，认为自己没有面子，对上级采取敬而远之的态度。这样的风险很大，因为你业绩低迷上级本身就不会满意，会对你的工作能力产生怀疑；如果再不了解工作状况和进度，还会认为你没有努力工作。时间一长，你就可能进入要被淘汰的黑名单了。</p>

<p>其实在每次的淘汰名单中，并不全是业绩最差的人，但不会主动找上级沟通的人却会占很大比例。</p>

<p>那位被辞退的员工还有一个重要原因，就在于他近期工作业绩并不明显，我得到的反馈只是正在进行中。至于是如何进行的、进行的情况如何，一直得不到明确答复。“用人不疑”是一条原则，但这是需要有不被怀疑的行动的。</p>

<h2 id="规则3-对于认为不合理的事情要通过正常的途径与方式去反馈:774be0051f1b4f02143bd69cbb43e499">规则3：对于认为不合理的事情要通过正常的途径与方式去反馈</h2>

<p>一个团队的决定有可能是对的，也有可能不太合理。但决定具备一定的权威性和强制力，也是保障一个团队正常运转的必要条件，是从大局和整体的角度出发的。员工先换位思考，如果对团队的利益有保障就要服从。如果有不尽完善的地方，要选择正常的程序和方式提出建议等待回复，只要决定没有触犯法规，员工应该无条件服从。</p>

<p>如果采取消极方式对团队的决定进行对抗，受伤害的只会是员工自己。</p>

<h2 id="规则4-切忌煽动同事与团队对抗:774be0051f1b4f02143bd69cbb43e499">规则4：切忌煽动同事与团队对抗</h2>

<p>职场中受委屈甚至不公平的事情都是正常的，员工可以选择合适的方式提出，也可以选择到执法部门寻求帮助。但是采取煽动闹事的方式解决问题，往往把自己推到一个更加不利的境地，因为这种方式是团队是绝对不能容忍的。结果问题没有解决，自己还被辞退。</p>

<h2 id="规则5-如果你不能为一个团队创造一定的价值-起码不要成为制造码放的因素:774be0051f1b4f02143bd69cbb43e499">规则5：如果你不能为一个团队创造一定的价值，起码不要成为制造码放的因素</h2>

<p>团队里成员形形色色个性各异，有的员工喜欢用小手腕制造麻烦、造谣惑众来达到一些目的。一个人的为人和能力在团队成员的长期合作中，大家都会有判断。</p>

<p>小手腕能让一个人得到短期利益，一旦其他成员了解了他以后，他便很难立足。要组织里长期生存下去，大聪明是必要的。</p>

<h2 id="规则6-对于上级安排的临时性工作-一定要及时反馈:774be0051f1b4f02143bd69cbb43e499">规则6：对于上级安排的临时性工作，一定要及时反馈</h2>

<p>有时上级会安排临时性的工作给你，这些工作可能非常紧急，上级会要求随时反馈完成期限，这也是让上级增进对你信任度的机会。</p>

<p>我遭遇过这样的员工。公司送货发生了车祸，导致货物大量破损，经销商拒绝接货。为避免更多的损失，我告诉负责该市场的业务代表，让他亲自参与这次事件的处理，并随时跟我保持联系。但我等到夜里十点也没有消息，打电话居然关机了。最后送货司机只得把产品又拉回了工厂，公司多付出了上万元的损失。第二天联系上他时，他居然说和朋友去喝酒给忘了。从此，我对他的工作能力与态度充满了质疑。</p>

<h2 id="规则7-成就上级从而成就自己:774be0051f1b4f02143bd69cbb43e499">规则7：成就上级从而成就自己</h2>

<p>工作使大家走到了一起，同事首先就是一种合作关系。上级所掌握的资源和影响力，对人在职场中的发展起到决定性作用。</p>

<p>职场上快速发展的人无疑都是善于和上级合作的，他们在做好份内事的同时，会积极帮助上级分担工作排忧解难。上级也会把更多的锻炼机会提供给他们，把自己的真经传授给他们。他们会逐步熟悉上级的工作内容和技巧，而这些都是一个人得到快速发展的重要条件。当上级进一步提升时，他首先会把升迁的机会推荐给他们。</p>

<p>在团队中这些人威信都比较高，工作起来阻力就会小，也更容易得到同事们和更高上级的肯定和重视。</p>

<p>成就上级从而成就自己绝对是一条重要的原则。当你在为上级偏心而抱怨时，是否该认真反思一下自己遵循了这个原则。机会真的不会从天而降的，更多时候要靠自己去争取。</p>

<h2 id="规则8-不要抱怨-不要背后讨论:774be0051f1b4f02143bd69cbb43e499">规则8：不要抱怨，不要背后讨论</h2>

<p>同事之间既有合作也有竞争，当你有牢骚要发或想讲上级坏话时，千万不要当着你的同事的面，即便这是你的“铁哥们”.也许在你逞口舌之快时，你的坏话已传到上级耳朵里，甚至已被加工渲染，这会让你非常被动。</p>

<p>当我做被管理者时，也曾因为当着同事的面发牢骚而深受其害。而在做管理者时，也经常接到不少的小报告。当你有牢骚或想说坏话时，最好找个没人的地方去自言自语吧。</p>

<h2 id="规则9-把事情做好的同时-把人做好:774be0051f1b4f02143bd69cbb43e499">规则9：把事情做好的同时，把人做好</h2>

<p>从进入职场开始，就要把塑造自己的品牌作为一项重要的事来做。而把事做好是基本的，同时也要把人做好。把人做好更是一个人品牌塑造的重要条件，你在职场上的声誉会决定职场的长度和宽度。</p>

<p>在现代的中国，人品依然是企业用人的重要标准。你的人品是需要大家通过与你共事看出来的，也是一个长期积累的过程。不仅要在单位内还要在行业内、在业界树立你良好形象。当然好人不是指长袖善舞、八面玲珑，而是人一定要学会承担责任，不去做有害他人和组织的事情。</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/golang/io2/">
        【原创】golang 的io(二)
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    <p>合理利用io包，可以优雅代码，
比如直接写beego里controller的context，可以更直观、将生产结果更好的嵌入自己的逻辑里</p>

<p>用法很多很多，个人日常用了集中，不断总结中，也欢迎大家给我发<a href="https://github.com/ianwoolf/myPages">pr</a>.</p>

<p>1.直接写</p>

<pre><code>func GenJsonRes(w http.ResponseWriter, status int, msg string, data interface{}) {
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json; charset=utf-8&quot;)
    w.WriteHeader(status)
    content, err := json.Marshal(Response{Status_code: status, Msg: msg, Data: data})
    if err != nil {
        http.Error(w, err.Error(), 500)
        return
    }
    fmt.Fprintf(w, &quot;%s&quot;, string(content))
}
</code></pre>

<p>2.把生成结果的的过程嵌入到自己的业务逻辑里</p>

<pre><code>type Response struct {
    Success bool          `json:&quot;success&quot;`
    Msg     string        `json:&quot;msg&quot;`
    Data    []interface{} `json:&quot;data&quot;`
}

func (r *Response) GenResponse(w http.ResponseWriter, status int) error {
    w.Header().Set(&quot;Content-Type&quot;, &quot;application/json; charset=utf-8&quot;)
    w.WriteHeader(status)
    if content, err := json.Marshal(r); err != nil {
        return err
    } else {
        fmt.Fprintf(w, &quot;%s&quot;, string(content))
    }
    return nil
}
</code></pre>

<p>3.官网例子，输出到标准输出</p>

<pre><code>func main() {
// A Buffer can turn a string or a []byte into an io.Reader.
    buf := bytes.NewBufferString(&quot;R29waGVycyBydWxlIQ==&quot;)
    dec := base64.NewDecoder(base64.StdEncoding, buf)
    io.Copy(os.Stdout, dec)
}
</code></pre>

<p>4.复制文件时，直接用file写入file</p>

<pre><code>func CopyFile(srcName, dstName string) (written int64, err error) {
    src, err := os.Open(srcName)
    defer src.Close()
    if err != nil {
        return
    }
    dst, err := os.OpenFile(dstName, os.O_WRONLY|os.O_CREATE, 0644)
    defer dst.Close()
    if err != nil {
        return
    }
    return io.Copy(dst, src)
}
</code></pre>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/docker/%E5%88%B6%E4%BD%9C%E5%B8%A6%E6%9C%89ssh%E7%9A%84ubantu%E9%95%9C%E5%83%8F/">
        制作带有ssh的docker镜像,转,小修改并亲测
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    

<h2 id="手动搞-然后commit:e26601a9b94b90b70d0c8c0bcf072033">手动搞，然后commit</h2>

<p><strong>个人最爱的方式,我喜欢手动搞出来,然后用dockerfile搞启动命令/环境/网络等</strong></p>

<p>步骤如下：</p>

<p>首先，使用我们最熟悉的 「-ti」参数来创建一个容器(我之前的小黑是14.10的，所以没用04的，直接用的lastext):<code>$ sudo docker run -ti ubuntu  /bin/bash</code></p>

<pre><code>root@fc1936ea8ceb:/# sshd
bash: sshd: command not found
</code></pre>

<p>使用 sshd 开启 ssh server 服务,发现没有安装这个服务,注意，我们在使用 「-ti /bin/bash」 进入容器后，获得的是 root 用户的bash</p>

<pre><code>root@fc1936ea8ceb:/# apt-get install openssh-server
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following extra packages will be installed:
ca-certificates krb5-locales libck-connector0 libedit2 libgssapi-krb5-2
 libidn11 libk5crypto3 libkeyutils1 libkrb5-3 libkrb5support0
 libpython-stdlib libpython2.7-minimal libpython2.7-stdlib libwrap0 libx11-6
。。。。
Do you want to continue? [Y/n] y    
。。。，，
Setting up ssh-import-id (3.21-0ubuntu1) ...
Processing triggers for libc-bin (2.19-0ubuntu6.6) ...
Processing triggers for ca-certificates (20130906ubuntu2) ...
Updating certificates in /etc/ssl/certs... 164 added, 0 removed; done.
Running hooks in /etc/ca-certificates/update.d....done.
Processing triggers for ureadahead (0.100.0-16) ...
</code></pre>

<ul>
<li>14.04的ubantu的docker镜像没有sshd，lastest是有的。<strong>如果要用04，还需要先升级下apt-get</strong></li>
</ul>

<p>需要建立一个文件夹<code>mkdir -p /var/run/sshd</code></p>

<pre><code># /usr/sbin/sshd -D &amp;
root@fc1936ea8ceb:/# netstat -ntlp
    Active Internet connections (only servers)
    Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
    tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      3238/sshd       
    tcp6       0      0 :::22                   :::*                    LISTEN      3238/sshd   
# mkdir root/.ssh
# vi /root/.ssh/authorized_keys  #把中控机或者常用机器的公钥填进去（如非有中控，推荐以后空着）
# sed -ri 's/session    required     pam_loginuid.so/#session    required     pam_loginuid.so/g' /etc/pam.d/sshd  #修改 ssh 服务的安全登陆配置

# 启动docker时执行的初始化脚本，这里写的启动ssh。这个应该做成开机启动，这里仅做示例
# vi /run.sh 
# chmod +x run.sh
# cat /run.sh
   #!/bin/bash
    /usr/sbin/sshd -D
</code></pre>

<p>然后我们退出，保存镜像</p>

<pre><code># exit
$ sudo docker commit  xxxx sshd:ubantu  #xxx为刚才容器的CONTAINER ID
$ sudo docker  images   # 查看是否有了
    REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
    sshd                ubuntu              7aef2cd95fd0        10 seconds ago      255.2 MB
    ubuntu              latest              ba5877dc9bec        3 months ago        192.7 MB
</code></pre>

<p><strong>我们来验证，启动一个container，连docker主机</strong></p>

<pre><code>$ sudo docker  run -p 100:22  -d sshd:ubuntu /run.sh  #启动容器，并映射端口 100 --&gt;22
    3ad7182aa47f9ce670d933f943fdec946ab69742393ab2116bace72db82b4895
$ sudo docker ps
#找一台机器，连过去试试

$ ssh root@xxxx -p 100   #xxxx 是docker主机的ip，100是端口号。  这个跟container启动方式有关
    。。。。
    Are you sure you want to continue connecting (yes/no)? yes
。。。。
root@3ad7182aa47f:~#
</code></pre>

<p><strong>成功登陆，镜像创建成功。</strong></p>

<p>run.sh 脚本内容</p>

<h2 id="dockerfile搞:e26601a9b94b90b70d0c8c0bcf072033">dockerfile搞</h2>

<p>首先，创建一个叫做 sshd_ubuntu 的文件夹，用于存放我们的 Dockerfile 、脚本文件、以及其他文件。</p>

<pre><code>$ mkdir sshd_ubuntu
$ cd sshd_ubuntu/
$ touch Dockerfile run.sh
$ ls
    Dockerfile  run.sh
</code></pre>

<p>编写 run.sh(启动sshd，同上) 和 authorized_keys（登陆公钥，根据自己情况选择）<code>$ cat ~/.ssh/id_rsa.pub &gt;authorized_keys</code></p>

<p><strong>重点来了，下面是 Dockerfile 的内容</strong></p>

<pre><code>FROM ubuntu:latest  #设置继承镜像


MAINTAINER dwj_zz@163.com #作者的信息
#更改源，根据自己需求，我改的网易的源
RUN echo &quot;deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse&quot; &gt; /etc/apt/sources.list
RUN echo &quot;deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list
RUN echo &quot;deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list
RUN echo &quot;deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list
RUN echo &quot;deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list
RUN apt-get update

#安装 ssh 服务
RUN apt-get install -y openssh-server
RUN mkdir -p /var/run/sshd
RUN mkdir -p /root/.ssh
#取消pam限制
RUN sed -ri 's/session    required     pam_loginuid.so/#session    required     pam_loginuid.so/g' /etc/pam.d/sshd

#复制配置文件到相应位置,并赋予脚本可执行权限
ADD authorized_keys /root/.ssh/authorized_keys
ADD run.sh /run.sh
RUN chmod 755 /run.sh

#开放端口
EXPOSE 22

#设置自启动命令
CMD [&quot;/run.sh&quot;]
</code></pre>

<p>创建镜像</p>

<pre><code>$ sudo docker build -t sshd:dockerfile .
    Sending build context to Docker daemon 5.632 kB
    Sending build context to Docker daemon
    Step 0 : FROM ubuntu:latest
     ---&gt; ba5877dc9bec
    Step 1 : MAINTAINER dwj_zz@163.com
     ---&gt; Running in 188d74d02d35
     ---&gt; 473eb019b331
    Removing intermediate container 188d74d02d35
    # 使用 Dockerfile 创建，他会帮你删除中间无用的文件层
    Step 2 : RUN echo &quot;deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse&quot; &gt; /etc/apt/sources.list
     ---&gt; Running in f52e2a583db5
     ---&gt; bd4ceef2ee19
    Removing intermediate container f52e2a583db5
    Step 3 : RUN echo &quot;deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list
......
    Step 15 : EXPOSE 22
     ---&gt; Running in 660a57c41b25
     ---&gt; 3ff9e88c4847
    Removing intermediate container 660a57c41b25
    Step 16 : CMD /run.sh
    ---&gt; Running in 5a0d838b6759
    ---&gt; 532f12181013
    Removing intermediate container 5a0d838b6759
    Successfully built 532f12181013
</code></pre>

<p>最后，返回告诉我们创建成功，镜像 id 号是532f12181013，让我们来查看下</p>

<pre><code>$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL     SIZE
sshd                dockerfile          532f12181013        7 seconds ago       242 MB
sshd                ubantu              08fdb11b77b5        About an hour ago   229.9 MB
</code></pre>

<p>最后，测试镜像，运行容器。同上，不在赘述。
<strong>注意到，后面跟上面手动搞镜像启动命令不一样，不需要在输入命令‘/run.sh’了，因为已经在 Dockerfile 中定义了自启动命令。</strong></p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/docker/%E7%94%A8docker%E8%B5%B7gin%E6%9C%8D%E5%8A%A1/">
        用docker起golang的gin服务
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    

<h3 id="首先启动docker:b6ce1d1065d693b2dafcce54d8ea230a">首先启动docker</h3>

<p>看到一个可耐的鲸鱼，下面有docker地址，如下语句</p>

<pre><code>docker is configured to use the default machine with IP 192.168.99.100
For help getting started, check out the docs at https://docs.docker.com
</code></pre>

<p>注意里面的ip，这是docker主机的ip，后面连接container的时候需要通过docker主机的端口转发过去</p>

<p>下面是查找、下载、导出镜像用到的语句</p>

<pre><code>docker search golang   查找镜像
docker  pull golang:1.4.2
docker save -o go-1.4.img golang:1.4.2   导出镜像
</code></pre>

<h3 id="开始一个container:b6ce1d1065d693b2dafcce54d8ea230a">开始一个container</h3>

<pre><code>docker run -it -p 10101:8080 -v `pwd`/code/go/src/:/go/src/:rw golang:1.4.2 go run /go/src/myLab/golang/gin/main.go

* -p进行端口转发，docker主机10101 转发到container的8080（gin server端口）
* -v进行挂载（绝对路径），机器的·pwd·/code/go/src,挂在的container的/go/src。注意依赖
* 加-d后台运行
</code></pre>

<p>Docker ip is 10101   这个端口被转发到container的8080</p>

<p>这样即可跑起来，可curl请求docker主机端口，转发到container进行访问</p>

<pre><code>curl 192.168.99.100:10101/room/
</code></pre>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/golang/io/">
        【转】golang 的io(一)
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    

<h3 id="io-包为i-o原语提供了基本的接口-它主要包装了这些原语的已有实现:1f9b02d070b8cc71a61fea0c5ae37919">io 包为I/O原语提供了基本的接口。它主要包装了这些原语的已有实现。</h3>

<p>由于这些接口和原语以不同的实现包装了低级操作，因此除非另行通知，否则客户端不应假定它们对于并行执行是安全的。</p>

<p>在io包中最重要的是两个接口：Reader和Writer接口。本章所提到的各种IO包，都跟这两个接口有关，也就是说，只要实现了这两个接口，它就有了IO的功能。</p>

<h5 id="reader接口:1f9b02d070b8cc71a61fea0c5ae37919">Reader接口</h5>

<p>Reader接口的定义如下：</p>

<pre><code>type Reader interface {
    Read(p []byte) (n int, err error)
}
</code></pre>

<p>官方文档中关于该接口方法的说明：</p>

<blockquote>
<p>Read 将 len(p) 个字节读取到 p 中。它返回读取的字节数 n（0 &lt;= n &lt;= len(p)） 以及任何遇到的错误。即使 Read 返回的 n &lt; len(p)，它也会在调用过程中使用 p 的全部作为暂存空间。若一些数据可用但不到 len(p) 个字节，Read 会照例返回可用的数据，而不是等待更多数据。
当 Read 在成功读取 n &gt; 0 个字节后遇到一个错误或EOF（end-of-file），它就会返回读取的字节数。它会从相同的调用中返回（非nil的）错误或从随后的调用中返回错误（同时 n == 0）。 一般情况的一个例子就是 Reader 在输入流结束时会返回一个非零的字节数，同时返回的err不是EOF就是nil。无论如何，下一个 Read 都应当返回 0, EOF。
调用者应当总在考虑到错误 err 前处理 n &gt; 0 的字节。这样做可以在读取一些字节，以及允许的 EOF 行为后正确地处理I/O错误。</p>
</blockquote>

<p>也就是说，当Read方法返回错误时，不代表没有读取到任何数据。调用者应该处理返回的任何数据，之后才处理可能的错误。</p>

<p>根据Go语言中关于接口和实现了接口的类型的定义，我们知道Reader接口的方法集只包含一个Read方法，因此，所有实现了Read方法的类型都实现 了io.Reader接口，也就是说，在所有需要io.Reader的地方，可以传递实现了Read()方法的类型的实例。</p>

<p>下面，我们通过具体例子来谈谈该接口的用法。</p>

<pre><code>func ReadFrom(reader io.Reader, num int) ([]byte, error) {
    p := make([]byte, num)
    n, err := reader.Read(p)
    if n &gt; 0 {
        return p[:n], nil
    }
    return p, err
}
</code></pre>

<p>ReadFrom函数将io.Reader作为参数，也就是说，ReadFrom可以从任意的地方读取数据，只要来源实现了io.Reader接口。比如，我们可以从标准输入、文件、字符串等读取数据，示例代码如下：
- 从标准输入读取</p>

<pre><code>`data, err = ReadFrom(os.Stdin, 11)`
</code></pre>

<ul>
<li><p>从普通文件读取，其中file是os.File的实例</p>

<p><code>data, err = ReadFrom(file, 9)</code></p></li>

<li><p>从字符串读取</p>

<p><code>data, err = ReadFrom(strings.NewReader(&quot;from string&quot;), 12)</code></p></li>
</ul>

<p><strong>小贴士</strong></p>

<p>io.EOF 变量的定义：<code>var EOF = errors.New(&quot;EOF&quot;)</code>，是error类型。根据reader接口的说明，在 n &gt; 0 且数据被读完了的情况下，返回的error有可能是EOF也有可能是nil。</p>

<h5 id="writer接口:1f9b02d070b8cc71a61fea0c5ae37919">Writer接口</h5>

<p>Writer接口的定义如下：</p>

<pre><code>type Writer interface {
    Write(p []byte) (n int, err error)
}
</code></pre>

<p>官方文档中关于该接口方法的说明：</p>

<blockquote>
<p>Write 将 len(p) 个字节从 p 中写入到基本数据流中。它返回从 p 中被写入的字节数 n（0 &lt;= n &lt;= len(p)）以及任何遇到的引起写入提前停止的错误。若 Write 返回的 n &lt; len(p)，它就必须返回一个非nil的错误。</p>
</blockquote>

<p>同样的，所有实现了Write方法的类型都实现了io.Writer接口。</p>

<p>在上个例子中，我们是自己实现一个函数接收一个io.Reader类型的参数。这里，我们通过标准库的例子来学习。</p>

<p>在fmt标准库中，有一组函数：Fprint/Fprintf/Fprintln，它们接收一个io.Wrtier类型参数（第一个参数），也就是说它们将数据格式化输出到io.Writer中。那么，调用这组函数时，该如何传递这个参数呢？</p>

<p>我们以fmt.Fprintln为例，同时看一下fmt.Println函数的源码。</p>

<pre><code>func Println(a ...interface{}) (n int, err error) {
  return Fprintln(os.Stdout, a...)
}
</code></pre>

<p>实现了io.Reader接口或io.Writer接口的类型</p>

<p>初学者看到函数参数是一个接口类型，很多时候有些束手无策，不知道该怎么传递参数。还有人问：标准库中有哪些类型实现了io.Reader或io.Writer接口？</p>

<p>通过本节上面的例子，我们可以知道，os.File同时实现了这两个接口。我们还看到 os.Stdin/Stdout这样的代码，它们似乎分别实现了 io.Reader/io.Writer接口。没错，实际上在os包中有这样的代码：</p>

<pre><code>var (
Stdin  = NewFile(uintptr(syscall.Stdin), &quot;/dev/stdin&quot;)
Stdout = NewFile(uintptr(syscall.Stdout), &quot;/dev/stdout&quot;)
Stderr = NewFile(uintptr(syscall.Stderr), &quot;/dev/stderr&quot;)
</code></pre>

<p>)
也就是说，Stdin/Stdout/Stderr 只是三个特殊的文件（即都是os.File的实例），自然也实现了io.Reader和io.Writer。</p>

<p>目前，Go文档中还没法直接列出实现了某个接口的所有类型。不过，我们可以通过查看标准库文档，列出实现了io.Reader或io.Writer接口的类型（导出的类型）：</p>

<p>os.File 同时实现了io.Reader和io.Writer</p>

<pre><code>- strings.Reader 实现了io.Reader
- bufio.Reader/Writer 分别实现了io.Reader和io.Writer
- bytes.Buffer 同时实现了io.Reader和io.Writer
- bytes.Reader 实现了io.Reader
- compress/gzip.Reader/Writer 分别实现了io.Reader和io.Writer
- crypto/cipher.StreamReader/StreamWriter 分别实现了io.Reader和io.Writer
- crypto/tls.Conn 同时实现了io.Reader和io.Writer
- encoding/csv.Reader/Writer 分别实现了io.Reader和io.Writer
- mime/multipart.Part 实现了io.Reader
</code></pre>

<p>除此之外，io包本身也有这两个接口的实现类型。如：</p>

<p>实现了Reader的类型：LimitedReader、PipeReader、SectionReader
实现了Writer的类型：PipeWriter</p>

<p>以上类型中，常用的类型有：os.File、strings.Reader、bufio.Reader/Writer、bytes.Buffer、bytes.Reader</p>

<p><strong>小贴士</strong></p>

<p>从接口名称很容易猜到，一般地，Go中接口的命名约定：接口名以er结尾。注意，这里并非强行要求，你完全可以不以 er 结尾。标准库中有些接口也不是以 er 结尾的。</p>

<h5 id="readerat和writerat接口:1f9b02d070b8cc71a61fea0c5ae37919">ReaderAt和WriterAt接口</h5>

<p><strong>ReaderAt接口</strong>的定义如下：</p>

<pre><code>type ReaderAt interface {
ReadAt(p []byte, off int64) (n int, err error)
}
</code></pre>

<p>官方文档中关于该接口方法的说明：</p>

<blockquote>
<p>ReadAt 从基本输入源的偏移量 off 处开始，将 len(p) 个字节读取到 p 中。它返回读取的字节数 n（0 &lt;= n &lt;= len(p)）以及任何遇到的错误。
当 ReadAt 返回的 n &lt; len(p) 时，它就会返回一个非nil的错误来解释 为什么没有返回更多的字节。在这一点上，ReadAt 比 Read 更严格。
即使 ReadAt 返回的 n &lt; len(p)，它也会在调用过程中使用 p 的全部作为暂存空间。若一些数据可用但不到 len(p) 字节，ReadAt 就会阻塞直到所有数据都可用或产生一个错误。 在这一点上 ReadAt 不同于 Read。
若 n = len(p) 个字节在输入源的的结尾处由 ReadAt 返回，那么这时 err == EOF 或者 err == nil。
若 ReadAt 按查找偏移量从输入源读取，ReadAt 应当既不影响基本查找偏移量也不被它所影响。
ReadAt 的客户端可对相同的输入源并行执行 ReadAt 调用。</p>
</blockquote>

<p>可见，ReaderAt接口使得可以从指定偏移量处开始读取数据。</p>

<p>简单示例代码如下：</p>

<pre><code>package main
    import (
    &quot;fmt&quot;
    &quot;strings&quot;
)
func main() {
    reader := strings.NewReader(&quot;Go语言学习园地&quot;)
    p := make([]byte, 6)
    n, err := reader.ReadAt(p, 2)
    if err != nil {
        panic(err)
    }
    fmt.Printf(&quot;%s, %d\n&quot;, p, n)
}
</code></pre>

<p>运行结果：</p>

<pre><code>语言, 6
</code></pre>

<p><strong>WriterAt接口</strong>的定义如下：</p>

<pre><code>type WriterAt interface {
WriteAt(p []byte, off int64) (n int, err error)
</code></pre>

<p>}
官方文档中关于该接口方法的说明：</p>

<blockquote>
<p>WriteAt 从 p 中将 len(p) 个字节写入到偏移量 off 处的基本数据流中。它返回从 p 中被写入的字节数 n（0 &lt;= n &lt;= len(p)）以及任何遇到的引起写入提前停止的错误。若 WriteAt 返回的 n &lt; len(p)，它就必须返回一个非nil的错误。
若 WriteAt 按查找偏移量写入到目标中，WriteAt 应当既不影响基本查找偏移量也不被它所影响。
若区域没有重叠，WriteAt 的客户端可对相同的目标并行执行 WriteAt 调用。</p>
</blockquote>

<p>我们可以通过该接口将数据写入数据流的特定偏移量之后。</p>

<p>通过简单示例来演示WriteAt方法的使用（os.File实现了WriterAt接口）：</p>

<pre><code>package main
import (
&quot;fmt&quot;
&quot;os&quot;
)
func main() {
file, err := os.Create(&quot;writeAt.txt&quot;)
if err != nil {
    panic(err)
}
defer file.Close()
file.WriteString(&quot;Golang中文社区——这里是多余的&quot;)
n, err := file.WriteAt([]byte(&quot;Go语言学习园地&quot;), 24)
if err != nil {
    panic(err)
}
fmt.Println(n)
}
</code></pre>

<p>打开文件WriteAt.txt，内容是：</p>

<pre><code>Golang中文社区——Go语言学习园地
</code></pre>

<p>分析：</p>

<p><code>file.WriteString(&quot;Golang中文社区——这里是多余的&quot;)</code> 往文件中写入<code>Golang中文社区——这里是多余的</code>，之后 <code>file.WriteAt([]byte(&quot;Go语言学习园地&quot;), 24)</code> 在文件流的offset=24处写入<code>Go语言学习园地</code>（会覆盖该位置的内容）。</p>

<h5 id="readerfrom-和-writerto-接口:1f9b02d070b8cc71a61fea0c5ae37919">ReaderFrom 和 WriterTo 接口</h5>

<p><strong>ReaderFrom</strong>的定义如下：</p>

<pre><code>type ReaderFrom interface {
ReadFrom(r Reader) (n int64, err error)
}
</code></pre>

<p>官方文档中关于该接口方法的说明：</p>

<blockquote>
<p>ReadFrom 从 r 中读取数据，直到 EOF 或发生错误。其返回值 n 为读取的字节数。除 io.EOF 之外，在读取过程中遇到的任何错误也将被返回。
如果 ReaderFrom 可用，Copy 函数就会使用它。
注意：ReadFrom方法不会返回err == EOF。</p>
</blockquote>

<p>下面的例子简单的实现将文件中的数据全部读取（显示在标准输出）：
    package main
    import (
        &ldquo;bufio&rdquo;
        &ldquo;os&rdquo;
    )
    func main() {
        file, err := os.Open(&ldquo;writeAt.txt&rdquo;)
        if err != nil {
            panic(err)
        }
        defer file.Close()
        writer := bufio.NewWriter(os.Stdout)
        writer.ReadFrom(file)
        writer.Flush()
    }</p>

<p>当然，我们可以通过ioutil包的ReadFile函数获取文件全部内容。其实，跟踪一下ioutil.ReadFile的源码，会发现其实也是通过ReadFrom方法实现（用的是bytes.Buffer，它实现了ReaderFrom接口）。</p>

<pre><code>func readAll(r io.Reader, capacity int64) (b []byte, err error) {
        buf := bytes.NewBuffer(make([]byte, 0, capacity))
        // If the buffer overflows, we will get bytes.ErrTooLarge.
        // Return that as an error. Any other panic remains.
        defer func() {
                e := recover()
                if e == nil {
                        return
                }
                if panicErr, ok := e.(error); ok &amp;&amp; panicErr == bytes.ErrTooLarge {
                        err = panicErr
                } else {
                        panic(e)
                }
        }()
        _, err = buf.ReadFrom(r)
        return buf.Bytes(), err
}
func ReadFile(filename string) ([]byte, error) {
        f, err := os.Open(filename)
        if err != nil {
                return nil, err
        }
        defer f.Close()
        // It's a good but not certain bet that FileInfo will tell us exactly how much to
        // read, so let's try it but be prepared for the answer to be wrong.
        var n int64

        if fi, err := f.Stat(); err == nil {
                // Don't preallocate a huge buffer, just in case.
                if size := fi.Size(); size &lt; 1e9 {
                        n = size
                }
        }
        // As initial capacity for readAll, use n + a little extra in case Size is zero,
        // and to avoid another allocation after Read has filled the buffer.  The readAll
        // call will read into its allocated internal buffer cheaply.  If the size was
        // wrong, we'll either waste some space off the end or reallocate as needed, but
        // in the overwhelmingly common case we'll get it just right.
        return readAll(f, n+bytes.MinRead)
}
</code></pre>

<p>如果不通过ReadFrom接口来做这件事，而是使用io.Reader接口，我们有两种思路：</p>

<ol>
<li>先获取文件的大小（File的Stat方法），之后定义一个该大小的[]byte，通过Read一次性读取</li>
<li>定义一个小的[]byte，不断的调用Read方法直到遇到EOF，将所有读取到的[]byte连接到一起</li>
</ol>

<p>代码实现如下：
方法１：</p>

<pre><code>package main
import (
&quot;fmt&quot;
&quot;os&quot;
)
func main() {
    file, err := os.Open(&quot;writeAt.txt&quot;)
if err != nil {
    panic(err)
}
defer file.Close()
stat, err := file.Stat()
if err != nil {
    fmt.Println(err)
}
size := stat.Size()
    a := make([]byte, size)
file.Read(a)
fmt.Println(string(a))
}
</code></pre>

<p>方法２：</p>

<pre><code>package main
import (
</code></pre>

<p>    &rdquo;fmt&rdquo;
    &rdquo;os&rdquo;
    )
    func main() {
        file, err := os.Open(&ldquo;writeAt.txt&rdquo;)
    if err != nil {
        panic(err)
    }
    defer file.Close()
    a := make([]byte, 5)
    var b []byte
    for n, err := file.Read(a); err == nil; n, err = file.Read(a) {
        b = append(b, a[:n]&hellip;)
    }
    fmt.Println(string(b))
    }</p>

<p><strong>提示</strong></p>

<p>通过查看 bufio.Writer或strings.Buffer 类型的ReadFrom方法实现，会发现，其实它们的实现和上面说的第2种思路类似。</p>

<p><strong>WriterTo</strong>的定义如下：</p>

<pre><code>type WriterTo interface {
WriteTo(w Writer) (n int64, err error)
}
</code></pre>

<p>官方文档中关于该接口方法的说明：</p>

<blockquote>
<p>WriteTo 将数据写入 w 中，直到没有数据可写或发生错误。其返回值 n 为写入的字节数。 在写入过程中遇到的任何错误也将被返回。
如果 WriterTo 可用，Copy 函数就会使用它。</p>
</blockquote>

<p>读者是否发现，其实ReaderFrom和WriterTo接口的方法接收的参数是io.Reader和io.Writer类型。根据io.Reader和io.Writer接口的讲解，对该接口的使用应该可以很好的掌握。</p>

<p>这里只提供简单的一个示例代码：将一段文本输出到标准输出</p>

<pre><code>reader := bytes.NewReader([]byte(&quot;Go语言学习园地&quot;))
reader.WriteTo(os.Stdout)
</code></pre>

<p>通过io.ReaderFrom和io.WriterTo的学习，我们知道，如果这样的需求，可以考虑使用这两个接口：“一次性从某个地方读或写到某个地方去。”</p>

<h5 id="seeker接口:1f9b02d070b8cc71a61fea0c5ae37919">Seeker接口</h5>

<p>接口定义如下：
    type Seeker interface {
    Seek(offset int64, whence int) (ret int64, err error)
}</p>

<p>官方文档中关于该接口方法的说明：
&gt; Seek 设置下一次 Read 或 Write 的偏移量为 offset，它的解释取决于 whence： 0 表示相对于文件的起始处，1 表示相对于当前的偏移，而 2 表示相对于其结尾处。 Seek 返回新的偏移量和一个错误，如果有的话。</p>

<p>也就是说，Seek方法用于设置偏移量的，这样可以从某个特定位置开始操作数据流。听起来和ReaderAt/WriteAt接口有些类似，不过Seeker接口更灵活，可以更好的控制读写数据流的位置。</p>

<p>简单的示例代码：获取倒数第二个字符（需要考虑UTF-8编码，这里的代码只是一个示例）</p>

<pre><code>package main
import (
&quot;fmt&quot;
&quot;strings&quot;
)
func main() {
reader := strings.NewReader(&quot;Go语言学习园地&quot;)
reader.Seek(-6, 2)
r, _, _ := reader.ReadRune()
fmt.Printf(&quot;%c\n&quot;, r)
}
</code></pre>

<p>运行结果：</p>

<pre><code>园
</code></pre>

<p><strong>小贴士</strong></p>

<p>whence的值，在os包中定义了相应的常量，应该使用这些常量</p>

<pre><code>const (
SEEK_SET int = 0 // seek relative to the origin of the file
SEEK_CUR int = 1 // seek relative to the current offset
SEEK_END int = 2 // seek relative to the end
)
</code></pre>

<h5 id="closer接口:1f9b02d070b8cc71a61fea0c5ae37919">Closer接口</h5>

<p>接口定义如下：</p>

<pre><code>type Closer interface {
Close() error
}
</code></pre>

<p>该接口比较简单，只有一个Close()方法，用于关闭数据流。</p>

<p>文件(os.File)、归档（压缩包）、数据库连接、Socket等需要手动关闭的资源都实现了Closer接口。
实际编程中，经常将Close方法的调用放在defer语句中。</p>

<p><strong>小提示</strong>
初学者容易写出这样的代码：</p>

<pre><code>file, err := os.Open(&quot;studygolang.txt&quot;)
        defer file.Close()
        if err != nil {
        ...
}
</code></pre>

<ul>
<li>当文件 studygolang.txt 不存在或找不到时，file.Close()会panic，因为file是nil。因此，应该将defer file.Close()放在错误检查之后。</li>
</ul>

<h5 id="其他接口:1f9b02d070b8cc71a61fea0c5ae37919">其他接口</h5>

<h6 id="bytereader和bytewriter:1f9b02d070b8cc71a61fea0c5ae37919">ByteReader和ByteWriter</h6>

<p>通过名称大概也能猜出这组接口的用途：读或写一个字节。接口定义如下：</p>

<pre><code>type ByteReader interface {
ReadByte() (c byte, err error)
}
type ByteWriter interface {
WriteByte(c byte) error
}
</code></pre>

<p>在标准库中，有如下类型实现了io.ByteReader或io.ByteWriter:
<span style="background-color: rgb(255, 0, 0);">- bufio.Reader/Writer 分别实现了io.ByteReader和io.ByteWriter
- bytes.Buffer 同时实现了io.ByteReader和io.ByteWriter
- bytes.Reader 实现了io.ByteReader
- strings.Reader 实现了io.ByteReader</span></p>

<p>接下来的示例中，我们通过bytes.Buffer来一次读取或写入一个字节（主要代码）：</p>

<pre><code>package main
import (
&quot;bytes&quot;
&quot;fmt&quot;
)
func main() {
var ch byte
fmt.Scanf(&quot;%c\n&quot;, &amp;ch)
              buffer := new(bytes.Buffer)
err := buffer.WriteByte(ch)
if err == nil {
    fmt.Println(&quot;写入一个字节成功！准备读取该字节……&quot;)
    newCh, _ := buffer.ReadByte()
    fmt.Printf(&quot;读取的字节：%c\n&quot;, newCh)
} else {
    fmt.Println(&quot;写入错误&quot;)
}
}
</code></pre>

<p>程序从标准输入接收一个字节（ASCII字符），调用buffer的WriteByte将该字节写入buffer中，之后通过ReadByte读取该字节。</p>

<p>一般地，我们不会使用bytes.Buffer来一次读取或写入一个字节。那么，这两个接口有哪些用处呢？</p>

<p>在标准库encoding/binary中，实现Varints读取，就需要一个io.ByteReader类型的参数，也就是说，它需要一个字节一个字节的读取。关于encoding/binary包在后面会详细介绍。</p>

<p>在标准库image/jpeg中，Encode函数的内部实现使用了ByteWriter写入一个字节。</p>

<p><strong>小贴士</strong>
可以通过在Go语言源码src/pkg中搜索&rdquo;io.ByteReader&rdquo;或&rdquo;io.ByteWiter&rdquo;，获得哪些地方用到了这两个接口。你会发现，这两个接口在二进制数据或归档压缩时用的比较多。</p>

<h6 id="bytescanner-runereader和runescanner:1f9b02d070b8cc71a61fea0c5ae37919">ByteScanner、RuneReader和RuneScanner</h6>

<p>将这三个接口放在一起，是考虑到与ByteReader相关或相应。</p>

<p>ByteScanner接口的定义如下：</p>

<pre><code>type ByteScanner interface {
    ByteReader
    UnreadByte() error
}
</code></pre>

<p>可见，它内嵌了ByteReader接口（可以理解为继承了ByteReader接口），UnreadByte方法的意思是：将上一次ReadByte的 字节还原，使得再次调用ReadByte返回的结果和上一次调用相同，也就是说，UnreadByte是重置上一次的ReadByte。注 意，UnreadByte调用之前必须调用了ReadByte，且不能连续调用UnreadByte。即：</p>

<pre><code>buffer := bytes.NewBuffer([]byte{'a', 'b'})
err := buffer.UnreadByte()
</code></pre>

<p>和</p>

<pre><code>package main
    import (
    &quot;bytes&quot;
    &quot;fmt&quot;
)
func main() {
    buffer := bytes.NewBuffer([]byte{'a', 'b'})
    buffer.ReadByte()
    buffer.ReadByte()
    err := buffer.UnreadByte()
    fmt.Println(err) //&lt;nil&gt;    
    err = buffer.UnreadByte()
    fmt.Println(err) //  bytes.Buffer: UnreadByte: previous operation was not a read
}
</code></pre>

<p>err都非nil，错误为：<code>bytes.Buffer: UnreadByte: previous operation was not a read</code></p>

<h6 id="runereader接口和bytereader类似-只是readrune方法读取单个utf-8字符-返回其rune和该字符占用的字节数-该接口在regexp包有用到:1f9b02d070b8cc71a61fea0c5ae37919">RuneReader接口和ByteReader类似，只是ReadRune方法读取单个UTF-8字符，返回其rune和该字符占用的字节数。该接口在regexp包有用到。</h6>

<p>######RuneScanner接口和ByteScanner类似，就不赘述了。</p>

<p>ReadCloser、ReadSeeker、ReadWriteCloser、ReadWriteSeeker、ReadWriter、WriteCloser和WriteSeeker接口</p>

<p>这些接口是上面介绍的接口的两个或三个组合而成的新接口。例如ReadWriter接口：</p>

<pre><code>type ReadWriter interface {
    Reader
    Writer
}
</code></pre>

<p>这是Reader接口和Writer接口的简单组合（内嵌）。</p>

<p>这些接口的作用是：有些时候同时需要某两个接口的所有功能，即必须同时实现了某两个接口的类型才能够被传入使用。可见，io包中有大量的&rdquo;小接口&rdquo;，这样方便组合为&rdquo;大接口&rdquo;。</p>

<h6 id="sectionreader-类型:1f9b02d070b8cc71a61fea0c5ae37919">SectionReader 类型</h6>

<p>SectionReader是一个struct（没有任何导出的字段），实现了 Read, Seek 和 ReadAt，同时，内嵌了 ReaderAt 接口。结构定义如下：</p>

<pre><code>type SectionReader struct {
    r     ReaderAt // 该类型最终的 Read/ReadAt 最终都是通过 r 的 ReadAt 实现
    base  int64    // NewSectionReader 会将 base 设置为 off
    off   int64    // 从 r 中的 off 偏移处开始读取数据
    limit int64    // limit - off = SectionReader 流的长度
}
</code></pre>

<p>从名称我们可以猜到，该类型读取数据流中部分数据。看一下</p>

<p><code>func NewSectionReader(r ReaderAt, off int64, n int64) *SectionReader</code></p>

<p>的文档说明就知道了：</p>

<p>NewSectionReader 返回一个 SectionReader，它从 r 中的偏移量 off 处读取 n 个字节后以 EOF 停止。</p>

<p>也就是说，SectionReader 只是内部（内嵌）ReaderAt表示的数据流的一部分：从 off 开始后的n个字节。</p>

<p>这个类型的作用是：方便重复操作某一段(section)数据流；或者同时需要ReadAt和Seek的功能。</p>

<p>由于该类型所支持的操作，前面都有介绍，因此提供示例代码了。</p>

<p>关于该类型在标准库中的使用，我们在 [archive/zip — zip归档访问]() 会讲到。</p>

<h6 id="limitedreader-类型:1f9b02d070b8cc71a61fea0c5ae37919">LimitedReader 类型</h6>

<p>LimitedReader 类型定义如下：</p>

<pre><code>type LimitedReader struct {
    R Reader // underlying reader，最终的读取操作通过 R.Read 完成
    N int64  // max bytes remaining
}
</code></pre>

<p>文档说明如下：</p>

<blockquote>
<p>从 R 读取但将返回的数据量限制为 N 字节。每调用一次 Read 都将更新 N 来反应新的剩余数量。
也就是说，最多只能返回 N 字节数据。
LimitedReader只实现了Read方法（Reader接口）。</p>
</blockquote>

<p>使用示例如下：</p>

<pre><code>package main
import (
    &quot;fmt&quot;
    &quot;io&quot;
    &quot;strings&quot;
)
func main() {
    content := &quot;This Is LimitReader Example&quot;
    reader := strings.NewReader(content)
    limitReader := &amp;io.LimitedReader{R: reader, N: 20}
    for limitReader.N &gt; 0 {
        tmp := make([]byte, 2)
        limitReader.Read(tmp)
        fmt.Printf(&quot;%s&quot;, tmp)
    }
}
</code></pre>

<p>运行结果：</p>

<pre><code>This Is LimitReader    
</code></pre>

<p>可见，通过该类型可以达到 <em>只允许读取一定长度数据</em> 的目的。</p>

<p>在io包中，LimitReader 函数的实现其实就是调用 LimitedReader：</p>

<pre><code>func LimitReader(r Reader, n int64) Reader { return &amp;LimitedReader{r, n} }
</code></pre>

<p>PipReader 和 PipWriter 类型</p>

<p>PipReader（一个没有任何导出字段的struct）是管道的读取端。它实现了io.Reader和io.Closer接口。</p>

<p><strong>关于 Read 方法的说明</strong>：
&gt; 从管道中读取数据。该方法会堵塞，直到管道写入端开始写入数据或写入端关闭了。如果写入端关闭时带上了error（即调用CloseWithError关闭），该方法返回的err就是写入端传递的error；否则err为EOF。</p>

<p>PipWriter（一个没有任何导出字段的struct）是管道的写入端。它实现了io.Writer和io.Closer接口。</p>

<p><strong>关于 Write 方法的说明</strong>：
&gt; 写数据到管道中。该方法会堵塞，直到管道读取端读完所有数据或读取端关闭了。如果读取端关闭时带上了error（即调用CloseWithError关闭），该方法返回的err就是读取端传递的error；否则err为 ErrClosedPipe。</p>

<p>其他方法的使用通过例子一起讲解：</p>

<pre><code>package main
import (
    &quot;errors&quot;
    &quot;fmt&quot;
    &quot;io&quot;
    &quot;time&quot;
)
func main() {
    Pipe()
}
func Pipe() {
    pipeReader, pipeWriter := io.Pipe()
    go PipeRead(pipeReader)
    PipeWrite(pipeWriter)
    time.Sleep(1e7)
}

func PipeWrite(pipeWriter *io.PipeWriter) {
    var (
        i   = 0
        err error
        n   int
    )
    data := []byte(&quot;Go语言学习园地&quot;)
    for _, err = pipeWriter.Write(data); err == nil; n, err = pipeWriter.Write(data) {
        i++
        if i == 3 {
            pipeWriter.CloseWithError(errors.New(&quot;输出3次后结束&quot;))
        }
    }
    fmt.Println(&quot;close 后输出的字节数：&quot;, n, &quot; error：&quot;, err)
}

func PipeRead(pipeReader *io.PipeReader) {
    var (
        err error
        n   int
    )
    data := make([]byte, 1024)
    for n, err = pipeReader.Read(data); err == nil; n, err = pipeReader.Read(data) {
        fmt.Printf(&quot;%s\n&quot;, data[:n])
    }
    fmt.Println(&quot;writer 端 closewitherror后：&quot;, err)
}
</code></pre>

<p>运行结果：</p>

<pre><code>Go语言学习园地
Go语言学习园地
Go语言学习园地
close 后输出的字节数： 0  error： io: read/write on closed pipe
writer 端 closewitherror后： 输出3次后结束
</code></pre>

<p>代码分析：</p>

<p>io.Pipe()用于创建创建一个同步的内存管道（synchronous in-memory pipe），函数签名：</p>

<pre><code>func Pipe() (*PipeReader, *PipeWriter)
</code></pre>

<p>它将 io.Reader 连接到 io.Writer。一端的读取匹配另一端的写入，直接在这两端之间复制数据；它没有内部缓存。它对于并行调用 Read 和 Write 以及其它函数或 Close 来说都是安全的，并行安全。 一旦等待的I/O结束，Close 就会完成。并行调用 Read 或并行调用 Write 也同样安全： 同种类的调用将按顺序进行控制。稍候我们会分析管道相关的源码。
正因为是同步的（其原理和无缓存channel类似），因此不能在一个goroutine中进行读和写。</p>

<h6 id="copy-和-copyn-函数:1f9b02d070b8cc71a61fea0c5ae37919">Copy 和 CopyN 函数</h6>

<p><strong>Copy 函数</strong>的：
    func Copy(dst Writer, src Reader) (written int64, err error)
函数文档：</p>

<blockquote>
<p>Copy 将 src 复制到 dst，直到在 src 上到达 EOF 或发生错误。它返回复制的字节数，如果有的话，还会返回在复制时遇到的第一个错误。
成功的 Copy 返回 err == nil，而非 err == EOF。由于 Copy 被定义为从 src 读取直到 EOF 为止，因此它不会将来自 Read 的 EOF 当做错误来报告。
若 dst 实现了 ReaderFrom 接口，其复制操作可通过调用 dst.ReadFrom(src) 实现。此外，若 dst 实现了 WriterTo 接口，其复制操作可通过调用 src.WriteTo(dst) 实现。</p>
</blockquote>

<p>代码：</p>

<pre><code>io.Copy(os.Stdout, strings.NewReader(&quot;Go语言学习园地&quot;))
</code></pre>

<p>直接将内容输出（写入Stdout中）。</p>

<p>我们甚至可以这么做：</p>

<pre><code>package main
import (
    &quot;fmt&quot;
    &quot;io&quot;
    &quot;os&quot;
)
func main() {
    io.Copy(os.Stdout, os.Stdin)//  可用来复制文件
    fmt.Println(&quot;Got EOF -- bye&quot;)
}
</code></pre>

<p>执行：echo &ldquo;Hello, World&rdquo; | go run main.go`</p>

<pre><code>func CopyFile(srcName, dstName string) (written int64, err error) {
        src, err := os.Open(srcName)
        defer src.Close()
        if err != nil {
                return
        }
        dst, err := os.OpenFile(dstName, os.O_WRONLY|os.O_CREATE, 0644)
        defer dst.Close()
        if err != nil {
                return
        }
        return io.Copy(dst, src)
}
</code></pre>

<p><strong>CopyN 函数</strong>的签名：</p>

<pre><code>func CopyN(dst Writer, src Reader, n int64) (written int64, err error)
</code></pre>

<p>函数文档：
&gt; CopyN 将 n 个字节从 src 复制到 dst。 它返回复制的字节数以及在复制时遇到的最早的错误。由于 Read 可以返回要求的全部数量及一个错误（包括 EOF），因此 CopyN 也能如此。
&gt; 若 dst 实现了 ReaderFrom 接口，复制操作也就会使用它来实现。
<span style="color:#FF0000;">注：只有当written＝n时，返回的err才为nil,否则都不为nil</span>
代码：</p>

<pre><code>io.CopyN(os.Stdout, strings.NewReader(&quot;Go语言学习园地&quot;), 8)
</code></pre>

<p>会输出：</p>

<pre><code>Go语言
</code></pre>

<h6 id="readatleast-和-readfull-函数:1f9b02d070b8cc71a61fea0c5ae37919">ReadAtLeast 和 ReadFull 函数</h6>

<p><strong>ReadAtLeast 函数</strong>的签名：</p>

<p>func ReadAtLeast(r Reader, buf []byte, min int) (n int, err error)
函数文档：
&gt; ReadAtLeast 将 r 读取到 buf 中，直到读了最少 min 个字节为止。它返回复制的字节数，如果读取的字节较少，还会返回一个错误。若没有读取到字节，错误就只是 EOF。如果一个 EOF 发生在读取了少于 min 个字节之后，ReadAtLeast 就会返回 ErrUnexpectedEOF。若 min 大于 buf 的长度，ReadAtLeast 就会返回 ErrShortBuffer。对于返回值，当且仅当 err == nil 时，才有 n &gt;= min。
一般可能不太会用到这个函数。使用时需要注意返回的error判断。</p>

<p><strong>ReadFull 函数</strong>的签名：
func ReadFull(r Reader, buf []byte) (n int, err error)
函数文档：
&gt; ReadFull 精确地从 r 中将 len(buf) 个字节读取到 buf 中。它返回复制的字节数，如果读取的字节较少，还会返回一个错误。若没有读取到字节，错误就只是 EOF。如果一个 EOF 发生在读取了一些但不是所有的字节后，ReadFull 就会返回 ErrUnexpectedEOF。对于返回值，当且仅当 err == nil 时，才有 n == len(buf)。
注意该函数和ReadAtLeast的区别：ReadFull 将buf读满；而ReadAtLeast是最少读取min个字节。</p>

<h6 id="writestring-函数:1f9b02d070b8cc71a61fea0c5ae37919">WriteString 函数</h6>

<p>这是为了方便写入string类型提供的函数，函数签名：</p>

<pre><code>func WriteString(w Writer, s string) (n int, err error)
</code></pre>

<p>当 w 实现了 WriteString 方法时，直接调用该方法，否则执行w.Write([]byte(s))。</p>

<h6 id="multireader-和-multiwriter-函数:1f9b02d070b8cc71a61fea0c5ae37919">MultiReader 和 MultiWriter 函数</h6>

<p>这两个函数的定义分别是：</p>

<pre><code>func MultiReader(readers ...Reader) Reader
func MultiWriter(writers ...Writer) Writer
</code></pre>

<p>它们接收多个Reader或Writer，返回一个Reader或Writer。我们可以猜想到这两个函数就是操作多个Reader或Writer就像操作一个。</p>

<p>事实上，在io包中定义了两个非导出类型：mutilReader和multiWriter，它们分别实现了io.Reader和io.Writer接口。类型定义为：</p>

<pre><code>type multiReader struct {
  readers []Reader
}
type multiWriter struct {
   writers []Writer
}
</code></pre>

<p>对于这两种类型对应的实现方法（Read和Write方法）的使用，我们通过例子来演示。</p>

<p><strong>MultiReader的使用</strong>：</p>

<pre><code>package main
import (
    &quot;bytes&quot;
    &quot;fmt&quot;
    &quot;io&quot;
    &quot;strings&quot;
)
func main() {
    readers := []io.Reader{
        strings.NewReader(&quot;from strings reader&quot;),
        bytes.NewBufferString(&quot;from bytes buffer&quot;),
    }
    reader := io.MultiReader(readers...)
    data := make([]byte, 0, 1024)
    var (
        err error
        n   int
    )
    for err != io.EOF {
        tmp := make([]byte, 512)
        n, err = reader.Read(tmp)
        if err == nil {
            data = append(data, tmp[:n]...)
        } else {
            if err != io.EOF {
                panic(err)
            }
        }
    }
    fmt.Printf(&quot;%s\n&quot;, data)
}
</code></pre>

<p>运行结果：</p>

<pre><code>from strings readerfrom bytes buffer
</code></pre>

<p>代码中首先构造了一个io.Reader的slice，由 strings.Reader 和 bytes.Buffer 两个实例组成，然后通过MultiReader得到新的Reader，循环读取新Reader中的内容。从输出结果可以看到，第 一次调用Reader的Read方法获取到的是slice中第一个元素的内容……也就是说，MultiReader只是逻辑上将多个Reader组合起 来，并不能通过调用一次Read方法获取所有Reader的内容。在所有的Reader内容都被读完后，Reader会返回EOF。</p>

<p><strong>MultiWriter的使用</strong>：</p>

<pre><code>package main
import (
    &quot;io&quot;
    &quot;os&quot;
)
func main() {
file, err := os.Create(&quot;tmp.txt&quot;)
    if err != nil {
        panic(err)
    }
    defer file.Close()
    writers := []io.Writer{
        os.Stdout,
        file,
    }
    writer := io.MultiWriter(writers...)
    writer.Write([]byte(&quot;hello,world&quot;))
}
</code></pre>

<p>这段程序执行后在生成tmp.txt文件，同时在文件和屏幕中都输出：hello world。</p>

<h6 id="teereader函数:1f9b02d070b8cc71a61fea0c5ae37919">TeeReader函数</h6>

<p>函数签名如下：</p>

<pre><code>func TeeReader(r Reader, w Writer) Reader
</code></pre>

<p>TeeReader 返回一个 Reader，它将从 r 中读到的数据写入 w 中。所有经由它处理的从 r 的读取都匹配于对应的对 w 的写入。它没有内部缓存，即写入必须在读取完成前完成。任何在写入时遇到的错误都将作为读取错误返回。</p>

<p>也就是说，我们通过Reader读取内容后，会自动写入到Writer中去。例子代码如下：</p>

<pre><code>package main
import (
    &quot;fmt&quot;
    &quot;io&quot;
    &quot;os&quot;
    &quot;strings&quot;
)
func main() {
    reader := io.TeeReader(strings.NewReader(&quot;Go语言学习园地&quot;), os.Stdout)
    p := make([]byte, 20)
    n, err := reader.Read(p)
    fmt.Println(string(p), n, err)
}
</code></pre>

<p>输出结果：</p>

<pre><code> Go语言学习园地Go语言学习园地 20 &lt;nil&gt;
</code></pre>

<p>这种功能的实现其实挺简单，无非是在Read完后执行Write。</p>

<p>至此，io所有接口、类型和函数都讲解完成。</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/golang/golang%E5%86%99%E6%96%87%E4%BB%B6%E7%9A%844%E4%B8%AD%E6%96%B9%E5%BC%8F/">
        golang 写文件的4中方式
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    <p>package main</p>

<pre><code>import (
    &quot;bufio&quot;  //缓存IO
    &quot;fmt&quot;
    &quot;io/ioutil&quot; //io 工具包
    &quot;io&quot;
    &quot;os&quot;
)

func check(e error) {
    if e != nil {
    panic(e)
    }
}

func checkFileIsExist(filename string) (bool) {
    var exist = true;
    if _, err := os.Stat(filename); os.IsNotExist(err) {
        exist = false;
    }
    return exist;
}

func main() {
    var wireteString = &quot;测试n&quot;
    var filename = &quot;./output1.txt&quot;;
    var f    *os.File
    var err1   error;

// 第一种方式: 使用 io.WriteString 写入文件 
    if checkFileIsExist(filename) {  //如果文件存在
        f, err1 = os.OpenFile(filename, os.O_APPEND, 0666)  //打开文件
        fmt.Println(&quot;文件存在&quot;);
    }else {
        f, err1 = os.Create(filename)  //创建文件
        fmt.Println(&quot;文件不存在&quot;);
    }
    check(err1)
    n, err1 := io.WriteString(f, wireteString) //写入文件(字符串)
    check(err1)
    fmt.Printf(&quot;写入 %d 个字节n&quot;, n);

//  第二种方式: 使用 ioutil.WriteFile 写入文件 
    var d1 = []byte(wireteString);
    err2 := ioutil.WriteFile(&quot;./output2.txt&quot;, d1, 0666)  //写入文件(字节数组)
    check(err2)

//  第三种方式:  使用 File(Write,WriteString) 写入文件  
    f, err3 := os.Create(&quot;./output3.txt&quot;)  //创建文件
    check(err3)
    defer f.Close()
    n2, err3 := f.Write(d1)  //写入文件(字节数组)
    check(err3)
    fmt.Printf(&quot;写入 %d 个字节n&quot;, n2)
    n3, err3 := f.WriteString(&quot;writesn&quot;) //写入文件(字节数组)
    fmt.Printf(&quot;写入 %d 个字节n&quot;, n3)
    f.Sync()

// 第四种方式:  使用 bufio.NewWriter 写入文件 
    w := bufio.NewWriter(f)  //创建新的 Writer 对象
    n4, err3 := w.WriteString(&quot;bufferedn&quot;)
    fmt.Printf(&quot;写入 %d 个字节n&quot;, n4)
    w.Flush()
    f.Close()
}
</code></pre>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/golang/%E4%B8%80%E8%A1%8C%E5%87%BD%E6%95%B0%E8%A7%A3%E5%86%B3http%E5%8F%91%E9%80%81/">
        【原创】一个函数解决http发送
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    

<p>golang发送http请求，是用Net/http包处理。http发送请求，其实都是由client.Do这个函数处理的。其他发送函数比如 Post、PostForm、Get函数，都是经过处理后调用client.DO进行处理。所以我们其实可以经过利用一个函数处理所有常用的发送请求。
附：</p>

<pre><code>#生成请求
func NewRequest(method, urlStr string, body io.Reader) (*Request, error)
#执行http请求
func (c *Client) Do(req *Request) (resp *Response, err error)
#生成带有超时的client（其他参数请自行google）
client := &amp;http.Client{Timeout: time.Duration(TimeoutDuration)}
</code></pre>

<h1 id="body参数形式-raw-form:6fbea2521e0bea875cffa974326c19fb">body参数形式&ndash;raw/form</h1>

<p>http中 form|raw的post，其实只是一个头文件的区别，本质都是body中的字符串。form只是编码之后，放进body。比raw的多了两步骤：编码+加header</p>

<pre><code>type Check struct {
        Timeout    time.Duration `json:&quot;timeout&quot;`
        Method     string        `json:&quot;measurement_type&quot;`
        Url        string
        PostBody   string
        BodyType   string `json:&quot;body_type&quot;`
        Result     QueryResult
}

func (check *Check) Post() error {
        TimeoutDuration := time.Duration(check.Timeout) * time.Second
        client := &amp;http.Client{Timeout: time.Duration(TimeoutDuration)}
        queryHeader := &quot;&quot;
        if check.BodyType == &quot;form&quot; {
                queryHeader = &quot;application/x-www-form-urlencoded&quot;
        } else if check.BodyType != &quot;raw&quot; {
                return errors.New(&quot;Unkown body type&quot;)
        }
        res, err := client.Post(check.Url, queryHeader, strings.NewReader(check.PostBody))
        if err != nil {
                return err
        }
        defer res.Body.Close()
        check.Result.Status = res.StatusCode
        check.Result.Body, err = ioutil.ReadAll(res.Body)
        return err
}
</code></pre>

<p>如下面调用   第一个例子提交form的时候，提交编码后的string放进body并加头，跟body的post是完全一样的。</p>

<pre><code>tmpForm := `tstring=xxx&amp;tint=1`
testCheck = &amp;check.Check{Url: &quot;http://127.0.0.1:8080/room2/&quot;, Timeout: 3, Method: &quot;POST&quot;, BodyType: &quot;form&quot;, PostBody: tmpForm}
err = testCheck.DoQuery()
if err != nil {
        t.Error(&quot;failed when get form query&quot;, testCheck)
}

tmpJson := `{&quot;tstring&quot;: &quot;x&quot;, &quot;tint&quot;: 1}`
testCheck = &amp;check.Check{Url: &quot;http://127.0.0.1:8080/room1/&quot;, Timeout: 3, Method: &quot;POST&quot;, BodyType: &quot;raw&quot;, PostBody: tmpJson}
err = testCheck.DoQuery()
if err != nil {
        t.Error(&quot;failed when get json query&quot;, testCheck)
}
</code></pre>

<h1 id="汇总-一个函数解决所有http请求:6fbea2521e0bea875cffa974326c19fb">汇总：一个函数解决所有http请求</h1>

<pre><code>type HttpQuery struct {
        Timeout  int
        Method   string
        Url      string
        BodyType string
        Body     []byte
        Result   HttpResult
}

type HttpResult struct {
        Status int
        Body   []byte
}

func (query *HttpQuery) DoQuery() error {
        url, _ := url.Parse(query.Url)
        TimeoutDuration := time.Duration(query.Timeout) * time.Second
        client := &amp;http.Client{Timeout: time.Duration(TimeoutDuration)}
        req, _ := http.NewRequest(query.Method, url.String(), bytes.NewBufferString(string(query.Body)))

        if query.Method != &quot;GET&quot; {
                queryHeader := &quot;&quot;
                if query.BodyType == &quot;form&quot; {
                        queryHeader = &quot;application/x-www-form-urlencoded&quot;
                } else if query.BodyType != &quot;raw&quot; {
                        return errors.New(&quot;Unkown body type&quot;)
                }
                req.Header.Set(&quot;Content-Type&quot;, queryHeader)
        }
        res, err := client.Do(req)
        if err != nil {
                return err
        }
        defer res.Body.Close()

        query.Result.Status = res.StatusCode
        query.Result.Body, err = ioutil.ReadAll(res.Body)
        if err != nil {
                return errors.New(&quot;error in read post body&quot;)
        }
        return nil
}
</code></pre>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/golang/%E6%97%A0%E7%BC%93%E5%AD%98channel%E5%8F%8A%E5%B8%B8%E7%94%A8%E6%B3%95/">
        【原创】无缓存channel及日常用法
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    

<h5 id="当没有对channel读取的操作的时候-发送操作会阻塞-看下面例子:aa1780b59ea5c50d8457e0a0fcd09cd3">当没有对channel读取的操作的时候，发送操作会阻塞。看下面例子</h5>

<pre><code>package main
import (
&quot;fmt&quot;
&quot;time&quot;
)

var (
    messages = make(chan string)//无缓存channel
    signals = make(chan bool)//无缓存channel
)

func res(cs chan string) {
    fmt.Println(&quot;begin listin...&quot;)
    for {
       msg := &lt;-cs//监听channel
       fmt.Println(&quot;received message&quot;, msg)
    }
}

func main() {
    go res(messages)//监听channel
    time.Sleep(1 * 1e9)// 注释掉这句，就send fail，执行default。，为啥

    msg := &quot;hi 2005&quot;
    select {
    case messages &lt;- msg:
        fmt.Println(&quot;sent message&quot;, msg)
    default:
        fmt.Println(&quot;no message sent&quot;)
    }

    select {
    case msg := &lt;-messages:
        fmt.Println(&quot;received message&quot;, msg)
    case sig := &lt;-signals:
        fmt.Println(&quot;received signal&quot;, sig)
    default:
        fmt.Println(&quot;no activity&quot;)
    }
time.Sleep(1 * 1e9)
}
</code></pre>

<h5 id="close-channel:aa1780b59ea5c50d8457e0a0fcd09cd3">close channel</h5>

<p>表明没有数据再发往通道了（任务完成）。这对于channel接受者是一个信号，可以被用来表明任务完成。</p>

<pre><code>package main
import &quot;fmt&quot;
func main() {
jobs := make(chan int, 5)
done := make(chan bool)
    go func() {
    for {
        j, more := &lt;-jobs
        if more {
            fmt.Println(&quot;received job&quot;, j)
        } else {
            fmt.Println(&quot;received all jobs&quot;)
            done &lt;- true
            return
        }
    }
}()
    for j := 1; j &lt;= 3; j++ {
    jobs &lt;- j
    fmt.Println(&quot;sent job&quot;, j)
}
close(jobs)
fmt.Println(&quot;sent all jobs&quot;)
    &lt;-done
}
</code></pre>

<p>结果：</p>

<pre><code>$ go run closing-channels.go 
sent job 1
received job 1
sent job 2
received job 2
sent job 3
received job 3
sent all jobs
received all jobs
</code></pre>

<h5 id="range-over-channel:aa1780b59ea5c50d8457e0a0fcd09cd3">Range over channel</h5>

<p>range channle之前，需要close掉channel，否则会hang住</p>

<pre><code>package main
import &quot;fmt&quot;
func main() {
    queue := make(chan string, 2)
queue &lt;- &quot;one&quot;
queue &lt;- &quot;two&quot;
        //This range iterates over each element as it’s received fromqueue. 
        //Because we closed the channel above, the iteration terminates after receiving the 2 elements. 
        //If we didn’tclose it we’d block on a 3rd receive in the loop.
    close(queue)
    for elem := range queue {
    fmt.Println(elem)
}
}
</code></pre>

<p>结果：</p>

<pre><code>$ go run range-over-channels.go
one
two
</code></pre>

<h5 id="生产者-消费者:aa1780b59ea5c50d8457e0a0fcd09cd3">生产者+消费者：</h5>

<pre><code>var done = make(chan bool)
var msgs = make(chan int)
func produce() {
    for i := 0; i &lt; 10; i++ {
        msgs &lt;- i
    }
    fmt.Println(&quot;Before closing channel&quot;)
    close(msgs)
    fmt.Println(&quot;Before passing true to done&quot;)
    done &lt;- true
    }
func consume() {
    for {
        msg := &lt;-msgs
        time.Sleep(100 * time.Millisecond)
        fmt.Println(&quot;Consumer: &quot;, msg)
      }
    }
func main() {
    go produce()
    go consume()
    &lt;-done
    fmt.Println(&quot;After calling DONE&quot;)
}
</code></pre>

<p>结果：</p>

<pre><code>Consumer:  0
Consumer:  1
Consumer:  2
Consumer:  3
Consumer:  4
Consumer:  5
Consumer:  6
Consumer:  7
Consumer:  8
Before closing channel
Before passing true to done
After calling DONE  sending
</code></pre>

<p>这里由于是无缓存channel，前一个没有读取的时候，再发送会阻塞，类似fifo。同样接收也会卡住，为了验证，增加输出，变成如下代码：</p>

<pre><code>func produce() {
    for i := 0; i &lt; 4; i++ {
        fmt.Println(&quot;sending&quot;)
        msgs &lt;- i
        fmt.Println(&quot;sent&quot;)
    }
    fmt.Println(&quot;Before closing channel&quot;)
    close(msgs)
    fmt.Println(&quot;Before passing true to done&quot;)
    done &lt;- true
}
func consume() {
    for msg := range msgs {
        fmt.Println(&quot;Consumer: &quot;, msg)
        time.Sleep(100 * time.Millisecond)
    }
}
</code></pre>

<p>结果</p>

<pre><code>Consumer:  0
sent
sending
Consumer:  1
sent
sending
Consumer:  2
sent
sending
Consumer:  3
sent
Before closing channel
Before passing true to done
After calling DONE
</code></pre>

<p>用close做完成通知,执行结果无返回
    package main</p>

<pre><code>import (
        &quot;fmt&quot;
        &quot;time&quot;
)

var done = make(chan bool)
var msgs = make(chan int)

func produce(num int) {
        for i := 0; i &lt; num; i++ {
                msgs &lt;- i
                time.Sleep(2 * time.Second)
        }
        done &lt;- true
}

func consume() {
        for {
                select {
                case msg, status := &lt;-msgs:
                        if status {
                                fmt.Println(&quot;Consumer: &quot;, msg)
                        } else {
                                fmt.Println(&quot;all worker is done&quot;)
                                return
                        }
                case &lt;-time.After(1 * time.Second):
                        fmt.Println(&quot;1s&quot;)
                case &lt;-done:
                        fmt.Println(&quot;all reveived is done&quot;)
                }
        }
}

func main() {
        num := 5
        go produce(num)
        go consume()
        time.Sleep(time.Duration(num) * 3 * time.Second)
        close(msgs)
        fmt.Println(&quot;quit....&quot;)
}
</code></pre>

<p>【常用】执行结果用channel通知执行结果
    package main</p>

<pre><code>import (
        &quot;fmt&quot;
        &quot;time&quot;
)

type Result struct {
        Success bool
        Msg     string
}

var WorkResult = make(chan Result)
var msgs = make(chan int)

func produce(num int) {
        for i := 0; i &lt; num; i++ {
                msgs &lt;- i
                time.Sleep(2 * time.Second)
        }
}

func consume() {
        for {
                select {
                case msg, status := &lt;-msgs:
                        if status {
                                fmt.Println(&quot;Consumer: &quot;, msg)
                                WorkResult &lt;- Result{Msg: &quot;work is done&quot;, Success: true}
                        } else {
                                fmt.Println(&quot;work channel is close&quot;)
                                return
                        }
                case &lt;-time.After(1 * time.Second):
                        fmt.Println(&quot;1s have no work to reseive&quot;)
                }
        }
}

func main() {
        num := 5
        go produce(num)
        go consume()
        for resultCnt := 0; resultCnt &lt; num; resultCnt++ {
                workResult := &lt;-WorkResult
                if workResult.Success {
                        fmt.Println(&quot;work success:&quot;, workResult.Msg)
                } else {
                        fmt.Println(&quot;work fail:&quot;, workResult.Msg)
                }
                fmt.Printf(&quot;reseive %d result, all is%d\n&quot;, resultCnt+1, num)
        }
        //time.Sleep(time.Duration(num) * 4 * time.Second)
        fmt.Println(&quot;all work return, reseive is done&quot;)
        close(msgs)
        fmt.Println(&quot;quit....&quot;)
}
</code></pre>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/golang/%E6%B5%8B%E8%AF%95%E6%8A%80%E6%9C%AF/">
        【转】golang测试技术
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    

<p>本篇文章内容来源于 Golang核心开发组成员 Andrew Gerrand在Google I/O 2014的一次主题分享“ Testing Techniques”，即介绍使用Golang开发 时会使用到的测试技术（主要针对 单元测试），包括基本技术、高级技术（并发测试、 mock/fake、 竞争条件测试、并发测试、内/外部测 试、vet工具等）等，感觉总结的很全面，这里整理记录下来，希望能给大家带来帮助。原Slide访问需要自己搭梯子。另外这里也要吐槽一 下：Golang官方站的slide都是以一种特有的golang artical的格式放出的，没法像pdf那样下载，在国内使用和传播极其不便。</p>

<h3 id="一-基础测试技术:0731d049fe69f4c0b41b2c4dde1a8d81">一、基础测试技术</h3>

<h4 id="测试go代码:0731d049fe69f4c0b41b2c4dde1a8d81">测试Go代码</h4>

<p>Go语言内置测试框架。</p>

<p>内置的测试框架通过testing包以及go test命令来提供测试功能。</p>

<p>下面是一个完整的测试strings.Index函数的完整测试文件：</p>

<pre><code>//strings_test.go (这里样例代码放入strings_test.go文件中)
package strings_test

import (
    “strings”
    “testing”
)

func TestIndex(t *testing.T) {
    const s, sep, want = “chicken”, “ken”, 4
    got := strings.Index(s, sep)
    if got != want {
        t.Errorf(“Index(%q,%q) = %v; want %v”, s, sep, got, want)// 注意原slide中 的got和want写反了
    }
}
</code></pre>

<p>测试</p>

<pre><code>$go test -v strings_test.go
=== RUN TestIndex
— PASS: TestIndex (0.00 seconds)
PASS
ok      command-line-arguments    0.007s
</code></pre>

<p>go test的-v选项是表示输出详细的执行信息。</p>

<p>将代码中的want常量值修改为3，我们制造一个无法通过的测试：</p>

<pre><code>$go test -v strings_test.go
=== RUN TestIndex
— FAIL: TestIndex (0.00 seconds)
strings_test.go:12: Index(“chicken”,”ken”) = 4; want 3
FAIL
exit status 1
FAIL    command-line-arguments    0.008s
</code></pre>

<h4 id="表驱动测试:0731d049fe69f4c0b41b2c4dde1a8d81">表驱动测试</h4>

<p>Golang的struct字面值(struct literals)语法让我们可以轻松写出表驱动测试。</p>

<pre><code>package strings_test

import (
    “strings”
    “testing”
)

func TestIndex(t *testing.T) {
    var tests = []struct {
        s   string
        sep string
        out int
    }{ {“”, “”, 0}, {“”, “a”, -1}, {“fo”, “foo”, -1}, {“foo”, “foo”, 0}, {“oofofoofooo”, “f”,2} }
for _, test := range tests {
    actual := strings.Index(test.s, test.sep)
    if actual != test.out {
        t.Errorf(“Index(%q,%q) = %v; want %v”,
        test.s, test.sep, actual, test.out)
        }
    }
}
</code></pre>

<p>测试</p>

<pre><code>$go test -v strings_test.go
=== RUN TestIndex
— PASS: TestIndex (0.00 seconds)
PASS
ok      command-line-arguments    0.007s
</code></pre>

<h4 id="t结构:0731d049fe69f4c0b41b2c4dde1a8d81">T结构</h4>

<p>*testing.T参数用于错误报告：</p>

<pre><code>t.Errorf(“got bar = %v, want %v”, got, want)
t.Fatalf(“Frobnicate(%v) returned error: %v”, arg, err)
t.Logf(“iteration %v”, i)
</code></pre>

<p>也可以用于enable并行测试(parallet test)：</p>

<pre><code>t.Parallel()
</code></pre>

<p>控制一个测试是否运行：</p>

<pre><code>if runtime.GOARCH == “arm” {
    t.Skip(“this doesn’t work on ARM”)
}
</code></pre>

<h4 id="运行测试:0731d049fe69f4c0b41b2c4dde1a8d81">运行测试</h4>

<p>我们用go test命令来运行特定包的测试。</p>

<p>默认执行当前路径下包的测试代码。</p>

<pre><code>$ go test
PASS
</code></pre>

<p>测试</p>

<pre><code>$ go test -v
=== RUN TestIndex
— PASS: TestIndex (0.00 seconds)
PASS
</code></pre>

<p>要运行工程下的所有测试，我们执行如下命令：</p>

<pre><code>$ go test github.com/nf/…
</code></pre>

<p>标准库的测试：
    $ go test std</p>

<blockquote>
<p>注：假设strings_test.go的当前目录为testgo，在testgo目录下执行go test都是OK的。但如果我们切换到testgo的上一级目录执行go test，我们会得到什么结果呢？</p>
</blockquote>

<pre><code>$go test testgo
can’t load package: package testgo: cannot find package “testgo” in any of:
/usr/local/go/src/pkg/testgo (from $GOROOT)
/Users/tony/Test/GoToolsProjects/src/testgo (from $GOPATH)
</code></pre>

<p>提示找不到testgo这个包，go test后面接着的应该是一个包名，go test会在GOROOT和GOPATH下查找这个包并执行包的测试。</p>

<h4 id="测试覆盖率:0731d049fe69f4c0b41b2c4dde1a8d81">测试覆盖率</h4>

<p>go tool命令可以报告测试覆盖率统计。</p>

<p>我们在testgo下执行go test -cover，结果如下：</p>

<pre><code>go build _/Users/tony/Test/Go/testgo: no buildable Go source files in /Users/tony/Test/Go/testgo
FAIL    _/Users/tony/Test/Go/testgo [build failed]
</code></pre>

<p>显然通过cover参数选项计算测试覆盖率不仅需要测试代码，还要有被测对象（一般是函数）的源码文件。</p>

<p>我们将目录切换到$GOROOT/src/pkg/strings下，执行go test -cover：</p>

<pre><code>$go test -v -cover
=== RUN TestReader
— PASS: TestReader (0.00 seconds)
… …
=== RUN: ExampleTrimPrefix
— PASS: ExampleTrimPrefix (1.75us)
PASS
coverage: 96.9% of statements
ok      strings    0.612s
</code></pre>

<p>go test可以生成覆盖率的profile文件，这个文件可以被go tool cover工具解析。</p>

<p>在$GOROOT/src/pkg/strings下面执行：</p>

<pre><code>$ go test -coverprofile=cover.out
</code></pre>

<p>会再当前目录下生成cover.out文件。</p>

<p>查看cover.out文件，有两种方法：</p>

<p>a) cover -func=cover.out</p>

<pre><code>$sudo go tool cover -func=cover.out
strings/reader.go:24:    Len                66.7%
strings/reader.go:31:    Read                100.0%
strings/reader.go:44:    ReadAt                100.0%
strings/reader.go:59:    ReadByte            100.0%
strings/reader.go:69:    UnreadByte            100.0%
… …
strings/strings.go:638:    Replace                100.0%
strings/strings.go:674:    EqualFold            100.0%
total:            (statements)            96.9%
</code></pre>

<p>b) 可视化查看</p>

<p>执行go tool cover -html=cover.out命令，会在/tmp目录下生成目录coverxxxxxxx，比如/tmp/cover404256298。目录下有一个 coverage.html文件。用浏览器打开coverage.html，即可以可视化的查看代码的测试覆盖情况。</p>

<p>关于go tool的cover命令，我的go version go1.3 darwin/amd64默认并不自带，需要通过go get下载。</p>

<pre><code>$sudo GOPATH=/Users/tony/Test/GoToolsProjects go get code.google.com/p/go.tools/cmd/cover
</code></pre>

<p>下载后，cover安装在$GOROOT/pkg/tool/darwin_amd64下面。</p>

<h3 id="高级测试技术:0731d049fe69f4c0b41b2c4dde1a8d81">高级测试技术</h3>

<h4 id="一个例子程序:0731d049fe69f4c0b41b2c4dde1a8d81">一个例子程序</h4>

<p>outyet是一个web服务，用于宣告某个特定Go版本是否已经打标签发布了。其获取方法：</p>

<pre><code>go get github.com/golang/example/outyet
</code></pre>

<blockquote>
<p>注：
go get执行后，cd $GOPATH/src/github.com/golang/example/outyet下，执行go run main.go。然后用浏览器打开<a href="http://localhost:8080即可访问该Web服务了。">http://localhost:8080即可访问该Web服务了。</a></p>
</blockquote>

<h4 id="测试http客户端和服务端:0731d049fe69f4c0b41b2c4dde1a8d81">测试Http客户端和服务端</h4>

<p>net/http/httptest包提供了许多帮助函数，用于测试那些发送或处理Http请求的代码。</p>

<h4 id="httptest-server:0731d049fe69f4c0b41b2c4dde1a8d81">httptest.Server</h4>

<p>httptest.Server在本地回环网口的一个系统选择的端口上listen。它常用于端到端的HTTP测试。</p>

<pre><code>type Server struct {
    URL      string // base URL of form http://ipaddr:port with no trailing slash
    Listener net.Listener

    // TLS is the optional TLS configuration, populated with a new config
    // after TLS is started. If set on an unstarted server before StartTLS
    // is called, existing fields are copied into the new config.
    TLS *tls.Config

    // Config may be changed after calling NewUnstartedServer and
    // before Start or StartTLS.
    Config *http.Server
}

func NewServer(handler http.Handler) *Server

func (*Server) Close() error
</code></pre>

<h4 id="httptest-server实战:0731d049fe69f4c0b41b2c4dde1a8d81">httptest.Server实战</h4>

<p>下面代码创建了一个临时Http Server，返回简单的Hello应答：</p>

<pre><code>ts := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    fmt.Fprintln(w, “Hello, client”)
}))
defer ts.Close()

res, err := http.Get(ts.URL)
if err != nil {
    log.Fatal(err)
}

greeting, err := ioutil.ReadAll(res.Body)
res.Body.Close()
if err != nil {
    log.Fatal(err)
}

fmt.Printf(“%s”, greeting)
</code></pre>

<h4 id="httptest-responserecorder:0731d049fe69f4c0b41b2c4dde1a8d81">httptest.ResponseRecorder</h4>

<p>httptest.ResponseRecorder是http.ResponseWriter的一个实现，用来记录变化，用在测试的后续检视中。</p>

<pre><code>type ResponseRecorder struct {
    Code      int           // the HTTP response code from WriteHeader
    HeaderMap http.Header   // the HTTP response headers
    Body      *bytes.Buffer // if non-nil, the bytes.Buffer to append written data to
    Flushed   bool
}
</code></pre>

<h4 id="httptest-responserecorder实战:0731d049fe69f4c0b41b2c4dde1a8d81">httptest.ResponseRecorder实战</h4>

<p>向一个HTTP handler中传入一个ResponseRecorder，通过它我们可以来检视生成的应答。</p>

<pre><code>handler := func(w http.ResponseWriter, r *http.Request) {
    http.Error(w, “something failed”, http.StatusInternalServerError)
}

req, err := http.NewRequest(“GET”, “http://example.com/foo”, nil)
if err != nil {
    log.Fatal(err)
}

w := httptest.NewRecorder()
handler(w, req)

fmt.Printf(“%d – %s”, w.Code, w.Body.String())
</code></pre>

<h4 id="竞争检测-race-detection:0731d049fe69f4c0b41b2c4dde1a8d81">竞争检测(race detection)</h4>

<p>当两个goroutine并发访问同一个变量，且至少一个goroutine对变量进行写操作时，就会发生数据竞争（data race）。</p>

<p>为了协助诊断这种bug，Go提供了一个内置的数据竞争检测工具。</p>

<p>通过传入-race选项，go tool就可以启动竞争检测。</p>

<pre><code>$ go test -race mypkg    // to test the package
$ go run -race mysrc.go  // to run the source file
$ go build -race mycmd   // to build the command
$ go install -race mypkg // to install the package
</code></pre>

<p>注：一个数据竞争检测的例子</p>

<p>例子代码：</p>

<pre><code>//testrace.go

package main

import “fmt”
import “time”

func main() {
    var i int = 0
    go func() {
    for {
        i++
        fmt.Println(“subroutine: i = “, i)
        time.Sleep(1 * time.Second)
    }
}()

for {
    i++
    fmt.Println(“mainroutine: i = “, i)
    time.Sleep(1 * time.Second)
    }
}
</code></pre>

<p>测试</p>

<pre><code>$go run -race testrace.go
mainroutine: i =  1

WARNING: DATA RACE
Read by goroutine 5:
main.func·001()
/Users/tony/Test/Go/testrace.go:10 +0×49

Previous write by main goroutine:
main.main()
/Users/tony/Test/Go/testrace.go:17 +0xd5

Goroutine 5 (running) created at:
main.main()
/Users/tony/Test/Go/testrace.go:14 +0xaf

subroutine: i =  2
mainroutine: i =  3
subroutine: i =  4
mainroutine: i =  5
subroutine: i =  6
mainroutine: i =  7
ubroutine: i =  8
</code></pre>

<h4 id="测试并发-testing-with-concurrency:0731d049fe69f4c0b41b2c4dde1a8d81">测试并发 （testing with concurrency)</h4>

<p>当测试并发代码时，总会有一种使用sleep的冲动。大多时间里，使用sleep既简单又有效。</p>

<p>但大多数时间不是”总是“。</p>

<p>我们可以使用Go的并发原语让那些奇怪不靠谱的sleep驱动的测试更加值得信赖。</p>

<h4 id="使用静态分析工具vet查找错误:0731d049fe69f4c0b41b2c4dde1a8d81">使用静态分析工具vet查找错误</h4>

<p>vet工具用于检测代码中程序员犯的常见错误：
– 错误的printf格式
– 错误的构建tag
– 在闭包中使用错误的range循环变量
– 无用的赋值操作
– 无法到达的代码
– 错误使用mutex
等等。</p>

<p>使用方法：<code>go vet [package]</code></p>

<h4 id="从内部测试:0731d049fe69f4c0b41b2c4dde1a8d81">从内部测试</h4>

<p>golang中大多数测试代码都是被测试包的源码的一部分。这意味着测试代码可以访问包种未导出的符号以及内部逻辑。就像我们之前看到的那样。</p>

<p>注：比如$GOROOT/src/pkg/path/path_test.go与path.go都在path这个包下。</p>

<h4 id="从外部测试:0731d049fe69f4c0b41b2c4dde1a8d81">从外部测试</h4>

<p>有些时候，你需要从被测包的外部对被测包进行测试，比如测试代码在package foo_test下，而不是在package foo下。</p>

<p>这样可以打破依赖循环，比如：</p>

<p>– testing包使用fmt
– fmt包的测试代码还必须导入testing包
– 于是，fmt包的测试代码放在fmt_test包下，这样既可以导入testing包，也可以同时导入fmt包。</p>

<h4 id="mocks和fakes:0731d049fe69f4c0b41b2c4dde1a8d81">Mocks和fakes</h4>

<p>通过在代码中使用interface，Go可以避免使用mock和fake测试机制。</p>

<p>例如，如果你正在编写一个文件格式解析器，不要这样设计函数：</p>

<p><code>func Parser(f *os.File) error</code></p>

<p>作为替代，你可以编写一个接受interface类型的函数:</p>

<p><code>func Parser(r io.Reader) error</code></p>

<p>和bytes.Buffer、strings.Reader一样，*os.File也实现了io.Reader接口。</p>

<h4 id="子进程测试:0731d049fe69f4c0b41b2c4dde1a8d81">子进程测试</h4>

<p>有些时候，你需要测试的是一个进程的行为，而不仅仅是一个函数。例如：</p>

<pre><code>func Crasher() {
    fmt.Println(“Going down in flames!”)
    os.Exit(1)
}
</code></pre>

<p>为了测试上面的代码，我们将测试程序本身作为一个子进程进行测试：</p>

<pre><code>func TestCrasher(t *testing.T) {
    if os.Getenv(“BE_CRASHER”) == “1″ {
        Crasher()
        return
    }
    cmd := exec.Command(os.Args[0], “-test.run=TestCrasher”)
    cmd.Env = append(os.Environ(), “BE_CRASHER=1″)
    err := cmd.Run()
    if e, ok := err.(*exec.ExitError); ok &amp;&amp; !e.Success() {
        return
    }
    t.Fatalf(“process ran with err %v, want exit status 1″, err)
}
</code></pre>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/linux/git/">
        【转】git 基本概念和用法
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    

<p>GIT基本概念和用法总结
guibin.beijing@gmail.com</p>

<p>在日常使用GIT过程中，经常会出错，比如无意间丢失了未提交的数据，回退版本时丢失了工作目录，等等。经过思考发现，所有这些错误都是因为对 GIT中一些基本的概念模糊而导致，因为对一些基本概念不清晰，导致对GIT每一条命令将会产生的结果不符合预期。下面我就梳理以下我经常碰到的问题相关 的基本概念。</p>

<ol>
<li><p>Working Directory（工作目录）
Git的工作目录是保存当前正在工作的文件所在的目录，和working tree是相同的意思。在这个目录中的文件可能会在切换branch时被GIT删除或者替换。这个目录是个临时目录，临时存储你从GIT库中取出的文件，这些文件一直会被保存，直到下次提交。</p></li>

<li><p>GIT Directory（GIT库目录）
项目的所有历史提交都被保存在了GIT库目录中，只要你不作回滚操作，它应该不会丢失。</p></li>

<li><p>GIT Index（Git索引）
Git index 可以看作是工作目录和Git库目录之间的暂存区，和staging area是相同的意思。可以使用Git index构建一组你准备一起提交的改变。Git Index和Git Staging area是同一个意思，都是指已经被add的但尚未commit的那些内容所在的区域。最简单的查看目前什么内容在index中的方法是使用git status命令。
• 命令中”Changes to be committed“中所列的内容是在Index中的内容，commit之后进入Git Directory。
• 命令中“Changed but not updated”中所列的内容是在Working Directory中的内容，add之后将进入Index。
• 命令中“Untracked files”中所列的内容是尚未被Git跟踪的内容，add之后进入Index。
哪些操作能够改变git index中的内容？
A). git add <path>&hellip;会将working directory中的内容添加进入git index。
B). git reset HEAD <path>&hellip;会将git index中path内容删除，重新放回working directory中。</p></li>

<li><p>git diff
git diff可以比较working tree同index之间，index和git directory之间，working tree和git directory之间，git directory中不同commit之间的差异，
• git diff [<path>&hellip;]：这个命令最常用，在每次add进入index前会运行这个命令，查看即将add进入index时所做的内容修改，即working directory和index的差异。
• git diff &ndash;cached [<path>&hellip;]：这个命令初学者不太常用，却非常有用，它表示查看已经add进入index但是尚未commit的内容同最后一次commit时的内容的差异。即index和git directory的差异。
• git diff &ndash;cached [<commit>] [<path>&hellip;]：这个命令初学者用的更少，也非常有用，它表示查看已经add进入index但是尚未commit的内容同指定的<commit>之间的差异，和上面一条很相似，差别仅仅<commit>，即index和git directory中指定版本的差异。
• git diff <commit> [<path>&hellip;]：这个命令用来查看工作目录和指定<commit>的commit之间的差别，如果要和Git directory中最新版比较差别，则<commit>=HEAD。如果要和某一个branch比较差别，<commit>=分支名字
• git diff <commit> <commit> [<path>&hellip;]：这个命令用来比较git directory中任意两个<commit>之间的差别，如果想比较任意一个<commit>和最新版的差别，把其中一个<commit>换成HEAD即可。</p></li>

<li><p>如何merge不同的分支
在git中，在执行任何命令时你一定要清楚，你在哪？对谁执行这个命令？
比如在创建新的branch时，执行命令：git branch 1.0-beta，这个命令是说在当前branch上，以当前branch为基准，创建一个新的branch，名叫1.0-beta。
在比如，当merge不同的branch时：
引用
git checkout 1.0-beta
git merge master
首先切换到1.0-beta branch上，然后将主干（master）上的代码合并到当前1.0-beta分支上。
merge完后，可能会由冲突，按照git的提示，编辑标识为&rdquo;CONFLICT (content)&ldquo;的文件，解决冲突后再次将冲突的文件add，commit后，merge完毕。</p></li>

<li><p>git reset
• 在一般使用中，如果发现错误的将不想staging的文件add进入index之后，想回退取消，则可以使用命令：git reset HEAD <file>&hellip;，同时git add完毕之后，git也会做相应的提示，比如：
引用</p>

<h1 id="changes-to-be-committed:1c1ef82aae62aeea8eedcb5f455b129b">Changes to be committed:</h1>

<p>#   (use &ldquo;git reset HEAD <file>&hellip;&rdquo; to unstage)</p>

<h1 id="new-file-test-scala:1c1ef82aae62aeea8eedcb5f455b129b">new file:   Test.scala</h1>

<p>• git reset [&ndash;hard|soft|mixed|merge|keep] [<commit>或HEAD]： 将当前的分支重设（reset）到指定的<commit>或者HEAD（默认，如果不显示指定commit，默认是HEAD，即最新的一次提 交），并且根据[mode]有可能更新index和working directory。mode的取值可以是hard、soft、mixed、merged、keep。下面来详细说明每种模式的意义和效果。
A). &ndash;hard：重设（reset） index和working directory，自从<commit>以来在working directory中的任何改变都被丢弃，并把HEAD指向<commit>。
B). &ndash;soft：index和working directory中的内容不作任何改变，仅仅把HEAD指向<commit>。这个模式的效果是，执行完毕后，自从<commit>以来的所有改变都会显示在git status的&rdquo;Changes to be committed&rdquo;中。
C). &ndash;mixed：仅reset index，但是不reset working directory。 这个模式是默认模式，即当不显示告知git reset模式时，会使用mixed模式。这个模式的效果是，working directory中文件的修改都会被保留，不会丢弃，但是也不会被标记成&rdquo;Changes to be committed&rdquo;，但是会打出什么还未被更新的报告。报告如下：
引用
Unstaged changes after reset:
M Test.Scala
M test.txt
D). &ndash;merge和&ndash;keep用的不多，在下面的例子中说明。</p></li>
</ol>

<p>下面列出一些git reset的典型的应用场景：
A) 回滚add操纵
引用
$ edit                                     (1)
$ git add frotz.c filfre.c
$ mailx                                    (2)
$ git reset                                (3)
$ git pull git://info.example.com/ nitfol  (4)</p>

<p>(1) 编辑文件frotz.c, filfre.c，做了些更改，并把更改添加到了index
(2) 查看邮件，发现某人要你pull，有一些改变需要你merge下来
(3) 然而，你已经把index搞乱了，因为index同HEAD commit不匹配了，但是你知道，即将pull的东西不会影响已经修改的frotz.c和filfre.c，因此你可以revert这两个文件的改变。 revert后，那些改变应该依旧在working directory中，因此执行git reset。
(4) 然后，执行了pull之后，自动merge，frotz.c和filfre.c这些改变依然在working directory中。</p>

<p>B) 回滚最近一次commit
引用
$ git commit &hellip;
$ git reset &ndash;soft HEAD^      (1)
$ edit                        (2)
$ git commit -a -c ORIG_HEAD  (3)</p>

<p>(1) 当提交了之后，你又发现代码没有提交完整，或者你想重新编辑一下提交的comment，执行git reset &ndash;soft HEAD^，让working tree还跟reset之前一样，不作任何改变。
HEAD^指向HEAD之前最近的一次commit。
(2) 对working tree下的文件做修改
(3) 然后使用reset之前那次commit的注释、作者、日期等信息重新提交。注意，当执行git reset命令时，git会把老的HEAD拷贝到文件.git/ORIG_HEAD中，在命令中可以使用ORIG_HEAD引用这个commit。commit 命令中 -a 参数的意思是告诉git，自动把所有修改的和删除的文件都放进stage area，未被git跟踪的新建的文件不受影响。commit命令中-c <commit> 或者 -C <commit>意思是拿已经提交的commit对象中的信息（作者，提交者，注释，时间戳等）提交，那么这条commit命令的意思就非常清晰了，把所有更改的文件加入stage area，并使用上次的提交信息重新提交。</p>

<p>C) 回滚最近几次commit，并把这几次commit放到叫做topic的branch上去。
引用
$ git branch topic/wip     (1)
$ git reset &ndash;hard HEAD~3  (2)
$ git checkout topic/wip   (3)
(1) 你已经提交了一些commit，但是此时发现这些commit还不够成熟，不能进入master分支，但你希望在新的branch上润色这些commit改动。因此执行了git branch命令在当前的HEAD上建立了新的叫做 topic/wip的分支。
(2) 然后回滚master branch上的最近三次提交。HEAD~3指向当前HEAD-3个commit的commit，git reset &ndash;hard HEAD~3即删除最近的三个commit（删除HEAD, HEAD^, HEAD~2），将HEAD指向HEAD~3。</p>

<p>D) 永久删除最后几个commit
引用
$ git commit &hellip;
$ git reset &ndash;hard HEAD~3   (1)
(1) 最后三个commit（即HEAD, HEAD^和HEAD~2）提交有问题，你想永久删除这三个commit。</p>

<p>E) 回滚merge和pull操作
引用
$ git pull                         (1)
Auto-merging nitfol
CONFLICT (content): Merge conflict in nitfol
Automatic merge failed; fix conflicts and then commit the result.
$ git reset &ndash;hard                 (2)
$ git pull . topic/branch          (3)
Updating from 41223&hellip; to 13134&hellip;
Fast-forward
$ git reset &ndash;hard ORIG_HEAD       (4)
(1) 从origin拉下来一些更新，但是产生了很多冲突，你暂时没有这么多时间去解决这些冲突，因此你决定稍候有空的时候再重新pull。
(2) 由于pull操作产生了冲突，因此所有pull下来的改变尚未提交，仍然再stage area中，这种情况下git reset &ndash;hard 与 git reset &ndash;hard HEAD意思相同，即都是清除index和working tree中被搞乱的东西。
(3) 将topic/branch合并到当前的branch，这次没有产生冲突，并且合并后的更改自动提交。
(4) 但是此时你又发现将topic/branch合并过来为时尚早，因此决定退滚merge，执行git reset &ndash;hard ORIG_HEAD回 滚刚才的pull/merge操作。说明：前面讲过，执行git reset时，git会把reset之前的HEAD放入.git/ORIG_HEAD文件中，命令行中使用ORIG_HEAD引用这个commit。同样 的，执行pull和merge操作时，git都会把执行操作前的HEAD放入ORIG_HEAD中，以防回滚操作。</p>

<p>F) 在被污染的working tree中回滚merge或者pull
引用
$ git pull                         (1)
Auto-merging nitfol
Merge made by recursive.
nitfol                |   20 +++++&mdash;-
&hellip;
$ git reset &ndash;merge ORIG_HEAD      (2)
(1) 即便你已经在本地更改了一些你的working tree，你也可安全的git pull，前提是你知道将要pull的内容不会覆盖你的working tree中的内容。
(2) git pull完后，你发现这次pull下来的修改不满意，想要回滚到pull之前的状态，从前面的介绍知道，我们可以执行git reset &ndash;hard ORIG_HEAD，但是这个命令有个副作用就是清空你的working tree，即丢弃你的本地未add的那些改变。为了避免丢弃working tree中的内容，可以使用git reset &ndash;merge ORIG_HEAD，注意其中的&ndash;hard 换成了 &ndash;merge，这样就可以避免在回滚时清除working tree。</p>

<p>G) 被中断的工作流程
在实际开发中经常出现这样的情形：你正在开发一个大的feature，此时来了一个紧急的bug需要修复，但是目前在working tree中的内容还没有成型，还不足以commit，但是你又必须切换的另外的branch去fix bug。请看下面的例子
引用
$ git checkout feature ;# you were working in &ldquo;feature&rdquo; branch and
$ work work work       ;# got interrupted
$ git commit -a -m &ldquo;snapshot WIP&rdquo;                 (1)
$ git checkout master
$ fix fix fix
$ git commit ;# commit with real log
$ git checkout feature
$ git reset &ndash;soft HEAD^ ;# go back to WIP state  (2)
$ git reset                                       (3)
(1) 这次属于临时提交，因此随便添加一个临时注释即可。
(2) 这次reset删除了WIP commit，并且把working tree设置成提交WIP快照之前的状态。
(3) 此时，在index中依然遗留着“snapshot WIP”提交时所做的uncommit changes，git reset将会清理index成为尚未提交&rdquo;snapshot WIP&rdquo;时的状态便于接下来继续工作。</p>

<p>(H) Reset单独的一个文件
假设你已经添加了一个文件进入index，但是而后又不打算把这个文件提交，此时可以使用git reset把这个文件从index中去除。
引用
$ git reset &ndash; frotz.c                      (1)
$ git commit -m &ldquo;Commit files in index&rdquo;     (2)
$ git add frotz.c                           (3)
(1) 把文件frotz.c从index中去除，
(2) 把index中的文件提交
(3) 再次把frotz.c加入index</p>

<p>(I) 保留working tree并丢弃一些之前的commit
假设你正在编辑一些文件，并且已经提交，接着继续工作，但是现在你发现当前在working tree中的内容应该属于另一个branch，与这之前的commit没有什么关系。此时，你可以开启一个新的branch，并且保留着working tree中的内容。
引用
$ git tag start
$ git checkout -b branch1
$ edit
$ git commit &hellip;                            (1)
$ edit
$ git checkout -b branch2                   (2)
$ git reset &ndash;keep start                    (3)
(1) 这次是把在branch1中的改变提交了。
(2) 此时发现，之前的提交不属于这个branch，此时你新建了branch2，并切换到了branch2上。
(3) 此时你可以用reset &ndash;keep把在start之后的commit清除掉，但是保持working tree不变。</p>

<ol>
<li><p>git revert
git revert用于回滚一些commit。对于一个或者多个已经存在的commit，去除由这些commit引入的改变，并且用一个新的commit来记录这个回滚操作。这个命令要求working tree必须是干净的。
git revert和git reset的功能很相似，但是有区别，具体如下。
git revert用于用一个commit来记录并回滚早前的commit，经常是一些错误的提交。如果你想干脆扔掉working tree中的东西，可以使用git reset &ndash;hard
比如
A) git revert HEAD~3：丢弃最近的三个commit，把状态恢复到最近的第四个commit，并且提交一个新的commit来记录这次改变。
B) git revert -n master~5..master~2：丢弃从最近的第五个commit（包含）到第二个（不包含）,但是不自动生成commit，这个revert仅仅修改working tree和index。</p></li>

<li><p>git revert 和 git reset的区别</p></li>

<li><p>git revert是用一次新的commit来回滚之前的commit，git reset是直接删除指定的commit。</p></li>

<li><p>在回滚这一操作上看，效果差不多。但是在日后继续merge以前的老版本时有区别。因为git revert是用一次逆向的commit“中和”之前的提交，因此日后合并老的branch时，导致这部分改变不会再次出现，但是git reset是之间把某些commit在某个branch上删除，因而和老的branch再次merge时，这些被回滚的commit应该还会被引入。</p></li>

<li><p>git reset 是把HEAD向后移动了一下，而git revert是HEAD继续前进，只是新的commit的内容和要revert的内容正好相反，能够抵消要被revert的内容。</p></li>

<li><p>如何删除远程分支
删除远程分支就是将本地的空分支push到远程即可。
引用
#查看远程分支
$ git ls-remote idc
Password:
fa7dc3cd254c6fff683e20722284565b92d869ff HEAD
14a62709ecadd11a266d234d19955f4679fa95ab refs/heads/cpp-1.0
34b38625bce0aa4d4a4e266e20bba3e0ccd1b97e refs/heads/cpp-1.0.RC1
3f40a21f20f51aaa74e2a6954b64d82506cd4adf refs/heads/cpp-1.1
2f795085d57b6784a6358d97dbd0d1227891b01a refs/heads/distri</p></li>
</ol>

<p>#删除远程叫做diftri的分支
$ git push idc :distri
Password:
To xxx@192.168.4.40:Project.git
- [deleted]         distri</p>

<p>#确认远程分支被删除
$ git ls-remote idc
Password:
fa7dc3cd254c6fff683e20722284565b92d869ff HEAD
14a62709ecadd11a266d234d19955f4679fa95ab refs/heads/cpp-1.0
34b38625bce0aa4d4a4e266e20bba3e0ccd1b97e refs/heads/cpp-1.0.RC1
3f40a21f20f51aaa74e2a6954b64d82506cd4adf refs/heads/cpp-1.1</p>

<ol>
<li><p>如何删除本地分支
使用git branch命令就可以删除本地分支，比如
引用
git branch -d toBeDelBranch</p></li>

<li><p>如何clone（克隆）远程仓库中的指定分支，而非默认的master分支
在git clone 命令中使用-b参数指定分支名字即可，比如将远端aiotrade.git上的levelIISZ-1.1分支克隆下来：
引用
git clone -b levelIISZ-1.1 username@192.168.4.40:aiotrade.git</p></li>
</ol>

<p>参考文献：
1. <a href="http://book.git-scm.com/3_basic_branching_and_merging.html">http://book.git-scm.com/3_basic_branching_and_merging.html</a>
2. git reset &ndash;help
3. git revert &ndash;help</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://106.186.127.250:1313/blog/%E7%9B%91%E6%8E%A7/%5B%E5%8E%9F%E5%88%9B%5Dconsum-%E5%BC%80%E5%A7%8B%E5%8F%8Aui/">
        【原创】consul开始及ui
      </a>
    </h1>

    <span class="post-date">Tue, Oct 20, 2015</span>

    

<h2 id="consul:ca111de2d7dbbaaa7aaa16407249693a">consul</h2>

<p>执行命令<code>./consul agent -server -bootstrap-expect 1 -data-dir /home/consul -node Litao-MacBook-Pro -dc sz-1 -bind 45.32.21.60 -ui-dir /media/monitor/ui -atlas=ATLAS_USERNAME/demo -atlas-token=xxx</code></p>

<h4 id="注意:ca111de2d7dbbaaa7aaa16407249693a">注意</h4>

<ul>
<li><code>-ui-dir</code>后面标注的是ui包的地址，也就是index.html所在地址，并且最后的<code>ui/</code>是访问ui的uri。</li>
<li><code>-atlas=ATLAS_USERNAME/demo -atlas-token=xxx</code>是否必须，还未验证</li>
</ul>

<h4 id="启动的时候-有些端口是回环地址-我用nginx做代理进行访问:ca111de2d7dbbaaa7aaa16407249693a">启动的时候，有些端口是回环地址，我用nginx做代理进行访问</h4>

<pre><code>    server {
        listen       80;
        server_name 45.32.21.60;
        charset utf-8;
        access_log  /home/xiaoju/nginx/logs/access.log;
        root /media/monitor;
                   index index.html;
        location / {
                   proxy_pass http://127.0.0.1:8500;
          }
        location /ui {
                   root /media/monitor;
                   index index.html;
          }
    }
</code></pre>

  </div>
  
</div>
</div>

  </body>
</html>
